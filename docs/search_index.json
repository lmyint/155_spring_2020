[["index.html", "STAT 155: Introduction to Statistical Modeling Welcome!", " STAT 155: Introduction to Statistical Modeling Welcome! Image source: xkcd This is the class manual for Introduction to Statistical Modeling (STAT 155) at Macalester College for the Spring 2020 semester. The content here was developed by Leslie Myint and draws upon material developed by the Macalester statistics faculty. For the most recent versions of my course websites and associated content, please see the Teaching section of my website. This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],["schedule.html", "Schedule Week 1: 1/24 Week 2: 1/27 - 1/31 Week 3: 2/3 - 2/7 Week 4: 2/10 - 2/14 Week 5: 2/17 - 2/21 Week 6: 2/24 - 2/28 Week 7: 3/2 - 3/6 Week 8: 3/9 - 3/13 Spring Break: 3/16 - 3/27 Week 9: 3/30 - 4/3 Week 10: 4/6 - 4/10 Week 11: 4/13 - 4/17 Week 12: 4/20 - 4/24", " Schedule Week 1: 1/24 Friday: Introductions; a taste of R and visualization Week 2: 1/27 - 1/31 Monday: Univariate visualization and summary measures Before class: Follow all instructions on the Software Setup page. Read sections 1.1, 2.1-2.4, and 2.6 in the STAT 155 Notes, and answer the Moodle questions under Reading Checks &gt; Data; Univariate Summaries and Visualization. Wednesday: Bivariate visualization and summary measures Before class: Read sections 2.5, 2.7, and 2.8 in the STAT 155 Notes, and answer the Moodle questions under Reading Checks &gt; Bivariate Summaries and Visualization. Friday: Continue with bivariate visualization. No new reading or Moodle questions. Just work on Homework 1. Homework 1 (on Moodle) is due Friday, January 31 at midnight. Week 3: 2/3 - 2/7 Monday: Simple linear regression models Before class: Read sections 3.1 to 3.6 in the STAT 155 Notes, and answer the Moodle questions under Reading Checks &gt; Simple Linear Regression (Part 1). Wednesday: Model evaluation and categorical predictors Before class: Read section 3.8 in the STAT 155 Notes only up through section 3.8.1 Indicator Variables, and answer the Moodle questions under Reading Checks &gt; Simple Linear Regression (Part 2). Friday: Quiz 1 in class Homework 2 (on Moodle) is due Thursday, February 13 at midnight. Week 4: 2/10 - 2/14 Reminder: Homework 2 (on Moodle) is due Thursday, February 13 at midnight. Monday: Multiple linear regression models Before class: Read sections 3.8.1 (Indicator Variables), 3.8.3 (Causation), and 3.8.6 (Dealing with Non-Linear Relationships) in the STAT 155 Notes, and answer the Moodle questions under Reading Checks &gt; Multiple Linear Regression. Wednesday: Multiple linear regression models Before class: No new reading. Friday: Interaction models Before class: Read section 3.8.2 (Interaction Variables) in the STAT 155 Notes, and answer the Moodle questions under Reading Checks &gt; Interaction Models. Week 5: 2/17 - 2/21 No new readings this week. Homework 3 is due Sunday, February 23 at midnight. Monday: Review multiple linear regression models and interaction. Wednesday: Variable redundancy, multicollinearity, and adjusted R-squared. Friday: Quiz 2 in class We’ll shift to new groups next week. Week 6: 2/24 - 2/28 New groups starting this week. For class on Monday, bring a pair of earbuds/headphones, and come prepared to listen to some loud music as part of an experiment! No class on Friday, but you must go to 2 capstone talks and submit a short response. On Moodle see Homework &gt; Capstone Days. Monday: Class experiment! Quantifying uncertainty Before class: Read sections 2.7.3 (Is this a Real Difference?) and 3.8.5 (Is the Difference Real?) in the STAT 155 Notes, and answer the Moodle questions under Reading Checks &gt; Quantifying Uncertainty. Wednesday: Causal inference Before class: Read sections 1.6 (Causal Inference) and 3.8.3 (Causation) in the STAT 155 Notes, and answer the Moodle questions under Reading Checks &gt; Causal Inference. Week 7: 3/2 - 3/6 No new readings this week - same topics that you had readings for last week. Monday: Bootstrapping. Wednesday: Causal inference. Friday: Quiz 3 in class Week 8: 3/9 - 3/13 Monday: Article discussion. Before class: Please read the article How racial discrimination in law enforcement actually works. Wednesday: Review for the midterm. Friday: Midterm in class Spring Break: 3/16 - 3/27 Week 9: 3/30 - 4/3 If Google/YouTube access is a problem, all videos and slides are also available on Moodle in the “Videos &amp; Slides” section. All Moodle questions are in the “Reading / Video Checks” section. Monday: Probability and odds. Video: Probability Essentials (YouTube link, Slides) Moodle questions: Probability Essentials Wednesday: Introduction to logistic regression. Video: Logistic Regression (YouTube link, Slides) Moodle questions: Logistic Regression Friday: Continuing with logistic regression. No new video or Moodle questions. Week 10: 4/6 - 4/10 Monday: Multiple logistic regression Wednesday: Sampling distributions and the normal distribution Video: Sampling Distributions (YouTube link, Slides) Friday: The central limit theorem and confidence intervals Video: Central Limit Theorem (Slides) Week 11: 4/13 - 4/17 Monday: Linear regression assumptions Video: Linear Regression Assumptions (YouTube link, Slides) Wednesday: Hypothesis testing Video: Hypothesis Testing (YouTube link, Slides) Friday: Continuing with hypothesis testing. Week 12: 4/20 - 4/24 Monday: Errors in hypothesis testing Video: Hypothesis testing errors (YouTube link, Slides) Wednesday: Continuing with hypothesis testing errors. From Friday 4/24 to the end of the semester, open office hours will be held in place of normal Zoom sessions. "],["software-setup.html", "Software Setup Troubleshooting", " Software Setup Before class on Monday, January 27, you should follow these instructions to set up the software that we’ll be using throughout the semester. Highly recommended: Change the default file download location for your internet browser Generally by default, internet browsers automatically save all files to the Downloads folder on your computer. This does not encourage good file organization practices. It is highly recommended that you change this option so that your browser asks you where to save each file before downloading it. This page has information on how to do this for the most common browsers. Required: Download R and RStudio FIRST: Download R here. You will see three links “Download R for …” Choose the link that corresponds to your computer. SECOND: Download RStudio here. Click the button under step 2 to install the version of RStudio recommended for your computer. Required: Please watch this video made by Professor Lisa Lendway that describes essential configuration options for RStudio. Required: Install required packages. An R package is an extra bit of functionality that will help us in our data analysis efforts in a variety of ways. Open RStudio and click inside the Console pane (by default, the bottom left pane). Copy and paste the following command into the Console. You should see the text below appear to the right of the &gt;, which is called the R prompt. After you paste, hit Enter. install.packages(c(&quot;ggplot2&quot;, &quot;dplyr&quot;, &quot;readr&quot;, &quot;rmarkdown&quot;)) You will see a lot of text from status messages appearing in the Console as the packages are being installed. Wait until you see the &gt; again. Enter the command library(ggplot2) and hit enter. If you see the message Error in library(ggplot2) : there is no package called ggplot2, then there was a problem installing this package. Jump down to the Troubleshooting section below. (Any other messages that appear are fine, and a lack of any messages is also fine.) Repeat the above step for the commands: library(dplyr) library(readr) library(rmarkdown) Quit RStudio. You’re done setting up! Optional: If you want a quick tour of RStudio before class on Monday, watch this video. It also shows you how to customize the layout and color scheme of RStudio. Troubleshooting Problem: You are on a Mac and getting the following error: Error: package or namespace load failed for ‘ggplot2’ in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]): there is no package called ‘rlang’ Here’s how to fix it: First install the suite of Command Line Tools for Mac using the instructions here. Next enter install.packages(\"rlang\") in the Console. Finally check that entering library(ggplot2) gives no errors. You should be good now for dplyr, readr, and rmarkdown. "],["welcome-and-motivation.html", "Topic 1 Welcome and Motivation Introductions A taste of data visualization in R", " Topic 1 Welcome and Motivation Introductions Get to know the others at your table. Share your names, preferred pronouns, and anything else that is important to you. A taste of data visualization in R Throughout the semester we’ll be using the statistical software R to analyze data. We’ll take a first look at R code today in the following activity. Board games are a favorite hobby of your instructor, and to her delight, there is a dataset containing information about many different board games and their ratings from the website BoardGameGeek.com! You will work through exploring this dataset in pairs, and the instructor will be circling around to help. For some phases of this exploration, you will need to have this page open to access the data description. This code may seem foreign at first, but over the semester you will have a lot of practice, and you’ll be able to write code like this by yourself at the end! Today, focus on getting a feel for what the code looks like and its potential for helping us gain insight. Warm-up The data are stored in an object (a container) called games. Let’s get a quick feel for this data. How many variables are present? Which are quantitative? Which are categorical? How many cases, or units of observation, do we have? How are the variables named / labeled? eyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6ImxpYnJhcnkoZ2dwbG90MilcbmxpYnJhcnkoZHBseXIpXG5saWJyYXJ5KHJlYWRyKVxuZ2FtZXMgPC0gcmVhZHI6OnJlYWRfY3N2KFwiaHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL3Jmb3JkYXRhc2NpZW5jZS90aWR5dHVlc2RheS9tYXN0ZXIvZGF0YS8yMDE5LzIwMTktMDMtMTIvYm9hcmRfZ2FtZXMuY3N2XCIpIiwic2FtcGxlIjoiIyBMb29rIGF0IHRoZSBmaXJzdCA2IHJvd3NcbmhlYWQoZ2FtZXMpXG5cbiMgSG93IG1hbnkgcm93cyBhbmQgY29sdW1ucyBkb2VzIHRoZSBkYXRhIGhhdmU/XG4jIFdoYXQgYXJlIGl0cyBkaW1lbnNpb25zP1xuZGltKGdhbWVzKSJ9 Phase 1 Use the code below to construct a visualization (a histogram) of average ratings for the games. What do you notice? What information can you gain from this plot? What do you think binwidth = 2 does? Try setting a different value for binwidth to make a plot that looks better to you. eyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6ImxpYnJhcnkoZ2dwbG90MilcbmxpYnJhcnkoZHBseXIpXG5saWJyYXJ5KHJlYWRyKVxuZ2FtZXMgPC0gcmVhZHI6OnJlYWRfY3N2KFwiaHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL3Jmb3JkYXRhc2NpZW5jZS90aWR5dHVlc2RheS9tYXN0ZXIvZGF0YS8yMDE5LzIwMTktMDMtMTIvYm9hcmRfZ2FtZXMuY3N2XCIpIiwic2FtcGxlIjoiIyBDcmVhdGUgYSBwbG90IG9mIGF2ZXJhZ2UgcmF0aW5ncyAoaGlzdG9ncmFtKVxuZ2dwbG90KGdhbWVzLCBhZXMoeCA9IGF2ZXJhZ2VfcmF0aW5nKSkgK1xuICAgIGdlb21faGlzdG9ncmFtKGJpbndpZHRoID0gMikifQ== Phase 2 Another way to visualize average ratings is shown below. Use the code below to construct a density plot of average ratings. Do you like this plot or the previous one better? Why? eyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6ImxpYnJhcnkoZ2dwbG90MilcbmxpYnJhcnkoZHBseXIpXG5saWJyYXJ5KHJlYWRyKVxuZ2FtZXMgPC0gcmVhZHI6OnJlYWRfY3N2KFwiaHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL3Jmb3JkYXRhc2NpZW5jZS90aWR5dHVlc2RheS9tYXN0ZXIvZGF0YS8yMDE5LzIwMTktMDMtMTIvYm9hcmRfZ2FtZXMuY3N2XCIpIiwic2FtcGxlIjoiIyBDcmVhdGUgYSBwbG90IG9mIGF2ZXJhZ2UgcmF0aW5ncyAoZGVuc2l0eSBwbG90KVxuZ2dwbG90KGdhbWVzLCBhZXMoeCA9IGF2ZXJhZ2VfcmF0aW5nKSkgK1xuICAgIGdlb21fZGVuc2l0eSgpIn0= Phase 3 Using code similar to either of the two above examples in Phases 1 and 2, what other variables might you visualize in a similar way? Try the code here. Make note of any interesting findings. eyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6ImxpYnJhcnkoZ2dwbG90MilcbmxpYnJhcnkoZHBseXIpXG5saWJyYXJ5KHJlYWRyKVxuZ2FtZXMgPC0gcmVhZHI6OnJlYWRfY3N2KFwiaHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL3Jmb3JkYXRhc2NpZW5jZS90aWR5dHVlc2RheS9tYXN0ZXIvZGF0YS8yMDE5LzIwMTktMDMtMTIvYm9hcmRfZ2FtZXMuY3N2XCIpIiwic2FtcGxlIjoiIyBWaXN1YWxpemUgc29tZSBvdGhlciB2YXJpYWJsZXMifQ== Phase 4 Using the code below, construct a visualization of average ratings broken down by minimum number of players. What do you notice? What is surprising? What is not surprising? eyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6ImxpYnJhcnkoZ2dwbG90MilcbmxpYnJhcnkoZHBseXIpXG5saWJyYXJ5KHJlYWRyKVxuZ2FtZXMgPC0gcmVhZHI6OnJlYWRfY3N2KFwiaHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL3Jmb3JkYXRhc2NpZW5jZS90aWR5dHVlc2RheS9tYXN0ZXIvZGF0YS8yMDE5LzIwMTktMDMtMTIvYm9hcmRfZ2FtZXMuY3N2XCIpIiwic2FtcGxlIjoiIyBWaXN1YWxpemUgYXZlcmFnZSByYXRpbmdzIGZvciBkaWZmZXJlbnQgbnVtYmVycyBvZiBtaW4uIHBsYXllcnNcbmdncGxvdChnYW1lcywgYWVzKHggPSBhdmVyYWdlX3JhdGluZykpICtcbiAgICBnZW9tX2hpc3RvZ3JhbSgpICtcbiAgICBmYWNldF93cmFwKH4gbWluX3BsYXllcnMpIn0= Phase 5 Using the code below, construct two alternate visualizations of average ratings broken down by minimum number of players. These plots use color instead of panels and also only keep games for which the minimum number of players ranges from 1 to 4. Which of the three visualizations do you like best? Why? eyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6ImxpYnJhcnkoZ2dwbG90MilcbmxpYnJhcnkoZHBseXIpXG5saWJyYXJ5KHJlYWRyKVxuZ2FtZXMgPC0gcmVhZHI6OnJlYWRfY3N2KFwiaHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL3Jmb3JkYXRhc2NpZW5jZS90aWR5dHVlc2RheS9tYXN0ZXIvZGF0YS8yMDE5LzIwMTktMDMtMTIvYm9hcmRfZ2FtZXMuY3N2XCIpIiwic2FtcGxlIjoiIyBTdWJzZXQgdGhlIGRhdGEgdG8gb25seSBrZWVwIGdhbWVzIHdoZXJlIG1pbl9wbGF5ZXJzIGlzIGZyb20gMSB0byA0XG5nYW1lc19zdWIgPC0gZHBseXI6OmZpbHRlcihnYW1lcywgbWluX3BsYXllcnMgPj0gMSwgbWluX3BsYXllcnMgPD0gNClcblxuIyBDb2xvcmVkIGhpc3RvZ3JhbXNcbmdncGxvdChnYW1lc19zdWIsIGFlcyh4ID0gYXZlcmFnZV9yYXRpbmcsIGZpbGwgPSBmYWN0b3IobWluX3BsYXllcnMpKSkgK1xuICAgIGdlb21faGlzdG9ncmFtKClcblxuIyBDb2xvcmVkIGRlbnNpdHkgcGxvdHNcbmdncGxvdChnYW1lc19zdWIsIGFlcyh4ID0gYXZlcmFnZV9yYXRpbmcsIGNvbG9yID0gZmFjdG9yKG1pbl9wbGF5ZXJzKSkpICtcbiAgICBnZW9tX2RlbnNpdHkoKSJ9 Phase 6 Using the code below, construct a visualization of the relationship between minimum recommended play time and average rating (a scatterplot). Is the plot useful? Why or why not? Using the dplyr::filter part of the Phase 5 code, subset the data to only keep games where the minimum recommended playtime is less than 1000 minutes. Then remake the scatterplot. Make note of any interesting findings. eyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6ImxpYnJhcnkoZ2dwbG90MilcbmxpYnJhcnkoZHBseXIpXG5saWJyYXJ5KHJlYWRyKVxuZ2FtZXMgPC0gcmVhZHI6OnJlYWRfY3N2KFwiaHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL3Jmb3JkYXRhc2NpZW5jZS90aWR5dHVlc2RheS9tYXN0ZXIvZGF0YS8yMDE5LzIwMTktMDMtMTIvYm9hcmRfZ2FtZXMuY3N2XCIpIiwic2FtcGxlIjoiIyBSZWxhdGlvbnNoaXAgYmV0d2VlbiBtaW4uIHJlY29tbWVuZGVkIHBsYXkgdGltZSBhbmQgYXZlcmFnZSByYXRpbmdcbmdncGxvdChnYW1lcywgYWVzKHggPSBtaW5fcGxheXRpbWUsIHkgPSBhdmVyYWdlX3JhdGluZykpICtcbiAgICBnZW9tX3BvaW50KCkgK1xuICAgIGdlb21fc21vb3RoKClcblxuIyBTdWJzZXQgdGhlIGRhdGEgdG8gb25seSBrZWVwIGdhbWVzIHdoZXJlIHRoZVxuIyBtaW5pbXVtIHJlY29tbWVuZGVkIHBsYXl0aW1lIGlzIGxlc3MgdGhhbiAxMDAwIG1pbnV0ZXNcblxuXG4jIFJlbGF0aW9uc2hpcCBiZXR3ZWVuIG1pbi4gcmVjb21tZW5kZWQgcGxheSB0aW1lIGFuZCBhdmVyYWdlIHJhdGluZyJ9 Phase 7 What other questions would you like to explore? Try them out below. If you would like to try something that is not part of the above examples, feel free to brainstorm with the instructor. eyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6ImxpYnJhcnkoZ2dwbG90MilcbmxpYnJhcnkoZHBseXIpXG5saWJyYXJ5KHJlYWRyKVxuZ2FtZXMgPC0gcmVhZHI6OnJlYWRfY3N2KFwiaHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL3Jmb3JkYXRhc2NpZW5jZS90aWR5dHVlc2RheS9tYXN0ZXIvZGF0YS8yMDE5LzIwMTktMDMtMTIvYm9hcmRfZ2FtZXMuY3N2XCIpIiwic2FtcGxlIjoiIyBZb3VyIG93biBleHBsb3JhdGlvbnMhIn0= "],["univariate-visualization-and-data-summaries.html", "Topic 2 Univariate Visualization and Data Summaries Learning Goals Discussion Exercises", " Topic 2 Univariate Visualization and Data Summaries Learning Goals Understand how bar charts, histograms, and density plots are constructed (not in full detail for a density plot) Identify the best type of plot to display a given variable and be able to construct those plots in R Clearly describe plots of quantitative variables using the concepts of shape, center, spread, and outliers Relate summary statistics of data to the concepts of shape, center, spread, and outliers Discussion When you interpret a plot of a quantitative variable, I expect you to discuss the following four aspects as part of a complete answer. Shape: How are values distributed along the observed range? What does the distribution of the variable look like? games &lt;- read_csv(&quot;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-12/board_games.csv&quot;) ggplot(games, aes(x = min_playtime)) + geom_density() Center: What is a typical value of the variable? Quantified with summary statistics like the mean and median. summary(games$min_playtime) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.00 25.00 45.00 80.88 90.00 60000.00 Spread: How spread out are the values? Are most values very close together or far apart? Quantified with summary statistics like the variance and standard deviation. Interpretation of the variance: it is the average (roughly) squared distance of each value to the mean. Units are the squared version of the original variable. Interpretation of the standard deviation: square root of the variance. Measures spread on the same scale as the original variable (same units as the original variable). var(games$min_playtime) ## [1] 406883.1 sd(games$min_playtime) ## [1] 637.8739 Outliers: Are there any values that are particularly high or low relative to the rest? A good paragraph putting all of these aspects together: The distribution of minimum playtimes is right-skewed with values ranging from 0 to 60,000 minutes. The center of the distribution is around 45 minutes (median). The mean is higher at about 80.88 minutes because of the high outliers (such as the game with a 60,000 minute minimum play time). Because of the outliers, it is difficult to see the spread of the bulk of the data clearly, and it is these outliers that contribute to the high standard deviation of 637.9 minutes. Qualities of a good paragraph: Describes the shape and range of the data Includes units Reports on the mean and median and explains any discrepancies between them Describes spread in terms of standard deviation Comments on the noteworthy visual features of the plot, including outliers Exercises A template RMarkdown document that you can start from is available here. As you proceed, put any new code that you encounter on your cheat sheet. Part 1 We have data on course evaluations for all courses offered in the Spring 2019 semester at Johns Hopkins University (source). We have the following pieces of information on each course: avg_rating: The average of student responses to the question asking them to rate the overall quality of the course using the Likert scale: 1 = Poor 2 = Weak 3 = Fair 4 = Good 5 = Excellent division: Either AS for Arts &amp; Sciences or EN for Engineering dept_name: Name of the department # Load required packages library(readr) library(ggplot2) # Read in the course evaluation data evals &lt;- read_csv(&quot;https://www.dropbox.com/s/3gayi1iq2p76kn0/jhu_evals.csv?dl=1&quot;) Exercise 1 The first step in any data analysis is to get acquainted with the data. Look at the first few rows, and obtain the dimensions of the dataset. # Look at the first 6 rows head(evals) # Get the dimensions of the dataset dim(evals) How many cases are there? (What are the cases?) What type of variable are the key ones described above? Exercise 2 Are the numbers of courses taught in the Arts &amp; Sciences and the Engineering divisions roughly the same? Before making the plot, make note of what your expectation is. Then compare to what you observe when you make the plot. (Clearly defining your expectations first is good scientific practice that is often not practiced enough to become habit.) ggplot(evals, aes(x = division)) + geom_bar() Exercise 3 Now we’ll look at the distribution of the avg_rating variable and associated summary statistics. Just like before, make note of what you expect the plots to look like before you make them. # Plots ggplot(evals, aes(x = avg_rating)) + geom_histogram() ggplot(evals, aes(x = avg_rating)) + geom_density() # Summary statistics # Adapt the code from the Discussion section to compute these ??? Write a good paragraph interpreting the histogram or density plot. (Discuss the 4 essential aspects.) What information is given by the tallest bar of the histogram? In what situations might you prefer a histogram to a density plot and vice-versa? Looking at the summary statistics, compare the mean to the median, and relate this to the shape of the distribution of average ratings. What would the distribution probably look like if the ordering of the mean and median were reversed? Part 2 When we are sitting behind a computer screen analyzing data, it can be easy to get caught up in the code, methods, or findings, and lose track of the human impact of our analysis. The analysis we did in Part 1 actually foreshadows a rather serious ethical concern for faculty. Exercise 4 Suppose that you were asked to rate the overall quality of one of your Fall courses on a 5-point scale. What kinds of things would you think about in giving your rating? Do you think you would give the same rating on a different day? In your opinion, do you think other students are using the same criteria as you? Exercise 5 In this last exercise, we’ll explore the misleading nature of the mean of Likert-scale responses. The datasets being read in below come from 3 different courses with 20 students each. For each student we have their rating of the overall course quality on the scale: 1 = Poor 2 = Weak 3 = Fair 4 = Good 5 = Excellent # Read in the course evaluation data course1 &lt;- read_csv(&quot;https://www.dropbox.com/s/qbw4ahys9mkxsqj/course1.csv?dl=1&quot;) course2 &lt;- read_csv(&quot;https://www.dropbox.com/s/tg8g0hchh435lx7/course2.csv?dl=1&quot;) course3 &lt;- read_csv(&quot;https://www.dropbox.com/s/b3cg2tdbpyjzwr6/course3.csv?dl=1&quot;) For each course, make an appropriate plot showing the distribution of student ratings. Put yourself in the professor’s shoes and briefly summarize the information that the plot gives. # Plot the distribution of ratings for each course ??? Now compute the mean rating for each course. You can adapt the code from the Discussion section to replace summary with mean to display only the mean. # Compute the mean rating for each course ??? Consider a school policy that ranks professors based on this mean rating and uses the rankings for evaluative and promotion purposes. Based on your investigations so far, would such a policy be fair? Is there a potential for it creating injustice? Extra! If you have time and want to explore more, try these exercises. Make a plot showing the number of courses by department. Is it effective? Add the following to the end of the code for your last plot. What does this code do? Add this to your cheat sheet. + theme(axis.text.x = element_text(angle = 90, hjust = 1)) Continue adding to the same plot the following code. What does it do? Modify it so that it is better suited to your plot. Add this to your cheat sheet. + labs(x = &quot;xxx&quot;, y = &quot;yyy&quot;, title = &quot;title&quot;) "],["bivariate-visualization-part-1.html", "Topic 3 Bivariate Visualization - Part 1 Learning Goals Exercises", " Topic 3 Bivariate Visualization - Part 1 Learning Goals Construct bivariate data visualizations of (1) two categorical variables and (2) one quantitative and one categorical variable Using good visualization principles, compare the strengths and weaknesses of these different visualizations Exercises A template RMarkdown document that you can start from is available here. As you proceed, put any new code that you encounter on your cheat sheet. Context and Setup Today we begin our data exploration for our first case study! We’ll be looking at a dataset of weightlifting competition results to understand how various factors relate to an athlete’s strength. The data originally come from Kaggle and OpenPowerlifting. # Load required packages library(readr) library(ggplot2) library(dplyr) # Read in the weightlifting data lifts &lt;- read_csv(&quot;https://www.dropbox.com/s/n6jko5m7ygeasoj/openpowerlifting_subs.csv?dl=1&quot;) Exercise 1 As always, we’ll start by getting acquainted with the data. Look at the first few rows, and obtain the dimensions of the dataset. # Look at the first 6 rows # Get the dimensions of the dataset How many cases are there? (What are the cases?) What kinds of variables do we have information on? (Are there broader categories of variables?) Look up any variables that are unfamiliar (for example, Wilks Coefficient). Exercise 2 Research question: Do males and females tend to use different types of equipment? The three barplots below give different ways of showing the Sex and Equipment variables. Which one is best suited to answering this research question and why? ggplot(lifts, aes(x = Sex, fill = Equipment)) + geom_bar() ggplot(lifts, aes(x = Sex, fill = Equipment)) + geom_bar(position = &quot;dodge&quot;) ggplot(lifts, aes(x = Sex, fill = Equipment)) + geom_bar(position = &quot;fill&quot;) Exercise 3 Your client for this case study (Leslie) is interested in using two of the variables to compute a third one. In particular, she wants to create a variable that is the ratio of total weight lifted to the athlete’s bodyweight. The code below creates a new variable called SWR (strength-to-weight ratio). Read through the code below and get a sense for what it is doing. If you have questions, ask the instructor. # The %&gt;% symbol is called a pipe. You can read it as: # take the output that comes before the pipe and feed it in as input to the function that comes after lifts &lt;- lifts %&gt;% mutate(SWR = TotalKg/BodyweightKg) Research question: How does strength-to-weight ratio differ between males and females? The code below makes different plots that can be used to explore this question. Before running the code, make note of what you expect. How might each contribute to answering the research question? Which one(s) would you choose to present to your client and why? ggplot(lifts, aes(x = SWR, fill = Sex)) + geom_histogram() ggplot(lifts, aes(x = SWR, fill = Sex)) + geom_histogram() + facet_grid(~ Sex) ggplot(lifts, aes(x = SWR, color = Sex)) + geom_density() ggplot(lifts, aes(x = Sex, y = SWR)) + geom_boxplot() Exercise 4 Did you notice anything unusual about the shape of the distribution of SWR in males and females? What group of athletes do you think is causing this peculiar shape? (Hint: you may have noticed this when you looked at the first few rows of the data.) Let’s filter out these individuals and remake your preferred plots from Exercise 3. Do you think that the rest of the analysis should proceed with these athletes filtered out? # Fill in the ??? below with a description of the athletes that you want to KEEP # See Day 1 - Phase 5 for an example lifts_subs &lt;- lifts %&gt;% filter(???) # Now remake your preferred plots from Exercise 3 Extra! If you have time and want to continue your explorations, try the following: Make plots showing the relationship between SWR and Equipment. Make plots showing the relationship between Wilks and Sex. Make plots showing the relationship between Wilks and Equipment. "],["bivariate-visualization-part-2.html", "Topic 4 Bivariate Visualization - Part 2 Learning Goals Exercises", " Topic 4 Bivariate Visualization - Part 2 Learning Goals Construct bivariate data visualizations of two quantiative variables Form ideas about the uses and building of statistical models Explain the uses, misuses, and limitations of the correlation coefficient Exercises A template RMarkdown document that you can start from is available here. We’ll continue using the dataset for our first case study: # Load required packages library(readr) library(ggplot2) library(dplyr) # Read in the weightlifting data lifts &lt;- read_csv(&quot;https://www.dropbox.com/s/n6jko5m7ygeasoj/openpowerlifting_subs.csv?dl=1&quot;) # Try to create the SWR variable without looking at your cheat sheet ??? Exercise 1 Using the plotting examples that we have gone over so far, generalize the code structure to create a scatterplot of SWR (y-axis) vs. BodyweightKg (x-axis). For no reason at all, I’ll say the word “point”. Before running the code, write down what you expect the plot to look like. In a few sentences describe the direction, form, strength, and any unusual features of the plot. Now add the following after the scatterplot: + geom_smooth(). What does this code do? Create another copy of your scatterplot code using geom_smooth(method = \"lm\") instead of geom_smooth(). What does the argument method = \"lm\" do? Compute the correlation coefficient between these two variables using the following. Is the correlation coefficient appropriate for summarizing this relationship? cor(lifts$SWR, lifts$BodyweightKg) Pause after this exercise, and we’ll discuss as a class. Exercise 2 Using the plot from exercise 1, try to estimate by hand the equation of the line shown on the plot. Exercise 3 Now use the code below to more precisely get the equation of the line. More specifically, this code fits a simple linear regression model to the data. There is a lot of output that gets printed, but focus only on the “Coefficients:” section and the “Estimate” column in that section. How does your estimated line compare? mod1 &lt;- lm(SWR ~ BodyweightKg, data = lifts) summary(mod1) Exercise 4 Do you think the simple linear regression model is any good? What features of the plot contribute to your decision? Using tools that we’ve learned so far, how might you try to quantify the quality of this model? How could we make the model better? What’s missing from it? Exercise 5 Your client for this case study is interested in learning how height is related to athlete strength (as measured by SWR or Wilks. However, height is not recorded in the data. Plan: how might we address this issue? Exercise 6 This last exercise takes a step away from our lifts dataset. Load the anscombe dataset using: data(anscombe) There are 4 sets of data within this dataset. x1 and y1, x2 and y2, x3 and y3, and x4 and y4. Compute the correlation coefficient between each of these pairs, and also make a scatterplot for each of these pairs. What is the message of this last exercise? "],["modeling-concepts-part-1.html", "Topic 5 Modeling Concepts (Part 1) Learning Goals New Groups! Discussion Exercises", " Topic 5 Modeling Concepts (Part 1) Learning Goals Construct simple linear regression models with a quantitative predictor in R Use these models to describe relationships and make predictions Develop two ideas of model quality: \\(R^2\\) and residual standard error Develop ideas of variation in estimates from sample to sample New Groups! In your new groups… Introduce yourselves Give your preferred pronouns If you had one extra hour of free time a day, how would you use it? Discussion Models A model is a simplified description of the world. Statistical models are mathematical descriptions that are informed by (estimated from) data. A simple linear regression model is a line model that can be mathematically represented as below: \\[ E[Y] = \\beta_0 + \\beta_1\\,X \\] \\(Y\\) is a quantitative response or outcome variable. e.g., House price \\(X\\) is a quantitative predictor or explanatory variable. e.g., Square footage of the house The \\(E[\\,\\,]\\) means “expected value of”: this is why lines model trends in averages and not individual-level trends \\(\\beta_0\\) and \\(\\beta_1\\) are the coefficients of the model. These coefficients are obtained from our data using the method of least squares. Interpreting the model coefficients When \\(X = 0\\), \\(E[Y] = \\beta_0\\). This means that \\(\\beta_0\\) is the expected value of the outcome when \\(X = 0\\). Note that this sometimes does not make sense! Centering the predictor can fix this. Don’t forget to report units in your interpretation! Case 1: \\(X = a \\qquad\\qquad\\qquad E[Y_1] = \\beta_0 + \\beta_1\\,a\\) Case 2: \\(X = a+1 \\qquad\\qquad E[Y_2] = \\beta_0 + \\beta_1\\,(a+1)\\) \\(E[Y_2] - E[Y_1] = \\beta_1\\) This means that \\(\\beta_1\\) is the expected change in the outcome per unit change in \\(X\\). Reporting units is important. The math shown here will be important when we extend these models to have multiple predictors. Fitting linear regression models in R # Fit the model and store the resulting information in &quot;mod&quot; mod &lt;- lm(y ~ x, data = your_dataset) # Display summary output of the model summary(mod) # Extract the residuals of the model residuals(mod) Exercises A template RMarkdown document that you can start from is available here. We will be looking at housing data from upstate New York. This dataset contains information on house price and structural characteristics for a large set of homes in Saratoga, NY. library(readr) library(ggplot2) library(dplyr) homes &lt;- read_tsv(&quot;http://sites.williams.edu/rdeveaux/files/2014/09/Saratoga.txt&quot;) Exercise 1 Get to know the data by displaying the first few rows and getting the dimensions. What are the cases? How many cases do we have? What kinds of variables do we have information on? Exercise 2 Always start an analysis with visualization! Make a plot that shows the relationship between Price (response) and Living.Area (predictor). Do you think a simple linear regression model is appropriate? Compute the correlation between Price and Living.Area. Carefully explain what this tells you about the slope of the least squares line. Exercise 3 Fit a linear regression model of Price as a function of Living.Area using the code below. mod1 &lt;- lm(Price ~ Living.Area, data = homes) summary(mod1) The two numbers in the “Estimate” column of the output give the intercept and the slope for Living.Area. Interpret both of these numbers. Is the intercept meaningful? We can center Living.Area at a more reasonable value. Let’s use 1000 square feet. Complete the code below to create a centered version of Living.Area. homes &lt;- homes %&gt;% ???(Living.Area.Shifted = Living.Area-1000) You can actually determine the coefficients of the Price ~ Living.Area.Shifted model by hand. Based on the summary output of mod1, work out what these new coefficients should be. Now check your answer to part (d) by fitting the model. mod2 &lt;- lm(???) summary(mod2) What is the residual for a $150,000 house that is 1000 square feet? Exercise 4 In this exercise, we’ll develop some intuition for ideas about how to quantify the quality of a model. Based on your plot from Exercise 2, do you think that our Price ~ Living.Area model is a good one? Explain by describing whether you think the variance of the residuals should be low or high for a good model. In the model summary output, there is a metric near the bottom called “Residual standard error”. The first number (ignore the “on XXXX degrees of freedom part”) is very close to the standard deviation of the residuals of the model. Verify this with the code below. Given that residual standard error is essentially a standard deviation, how do you think we can interpret this number? mod1 %&gt;% residuals() %&gt;% sd() Do you think that the variance of the residuals could ever be larger than the variance of the house prices? Why or why not? There is a metric for linear regression models called \\(R^2\\) which is displayed in the model summary output near the bottom just after “Multiple R-squared”. This number is computed as: 1 - Var(residuals)/Var(response). Do you think this number should be high or low for a good model? # If you are curious about checking the calculation 1-(var(residuals(mod1))/var(homes$Price)) Exercise 5 We only used a sample of Saratoga homes to estimate $113.123 as the slope for Living.Area. Based on your scatterplot from Exercise 2, how much do you think that slope estimate would change if we had a different sample of houses? A lot? A little? What are you thinking about as you formulate your opinion? "],["modeling-concepts-part-2.html", "Topic 6 Modeling Concepts (Part 2) Learning Goals Warm-up Discussion Exercises", " Topic 6 Modeling Concepts (Part 2) Learning Goals Practice simple linear regression modeling concepts: model formula, coefficient interpretations, predicted values, residuals Develop two ideas of model quality: \\(R^2\\) and residual standard error Understand how categorical predictors are incorporated in linear regression models Warm-up mod1 &lt;- lm(Price ~ Age, data = homes) summary(mod1) ## ## Call: ## lm(formula = Price ~ Age, data = homes) ## ## Residuals: ## Min 1Q Median 3Q Max ## -222183 -66299 -22232 43147 564995 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 229728.46 3218.18 71.385 &lt; 2e-16 *** ## Age -636.26 79.66 -7.987 2.5e-15 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 96700 on 1726 degrees of freedom ## Multiple R-squared: 0.03564, Adjusted R-squared: 0.03508 ## F-statistic: 63.79 on 1 and 1726 DF, p-value: 2.502e-15 Write the regression model formula using numbers from this output. Interpret all coefficients in this model. For a 50 year old house whose price is $100,000, what is the residual? Discussion What can we quantify about residuals to measure model quality? Not the sum or the mean of residuals (will always be zero) Residual standard error: essentially equal to the standard deviation of the residuals Scale of residual standard error changes with the scale of the data (e.g., house prices versus strength-to-weight ratio) Can we put the variance of the residuals on a nicer scale? Say from 0 to 1? Yes, we can. Some facts: \\[ \\hbox{Var}(\\hbox{response}) = \\hbox{Var}(\\hbox{residuals}) + \\hbox{Var}(\\hbox{predicted values}) \\] \\[ \\hbox{Total variation} = \\hbox{Unexplained variation} + \\hbox{Explained variation} \\] \\(R^2\\): What fraction of total variation in the response is explained by the model? Hopefully a lot. Which would mean that there is relatively little unexplained variation. Ranges from 0 to 1 \\[ \\begin{align*} R^2 &amp;= \\frac{\\hbox{Var}(\\hbox{predicted values})}{\\hbox{Var}(\\hbox{response})} \\\\ &amp;= 1 - \\frac{\\hbox{Var}(\\hbox{residuals})}{\\hbox{Var}(\\hbox{response})} \\end{align*} \\] mod1 &lt;- lm(Price ~ Living.Area, data = homes) summary(mod1) ## ## Call: ## lm(formula = Price ~ Living.Area, data = homes) ## ## Residuals: ## Min 1Q Median 3Q Max ## -277022 -39371 -7726 28350 553325 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 13439.394 4992.353 2.692 0.00717 ** ## Living.Area 113.123 2.682 42.173 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 69100 on 1726 degrees of freedom ## Multiple R-squared: 0.5075, Adjusted R-squared: 0.5072 ## F-statistic: 1779 on 1 and 1726 DF, p-value: &lt; 2.2e-16 Residual standard error: $69100 This describes the amount of spread in the residuals. What qualifies as “high”? Imagine that your residual changed by that much. Is that a lot? \\(R^2\\) (Multiple R-squared): 0.5075 50.75% of the variation in house prices is explained by a simple linear regression model with square footage as a predictor What qualifies as “high”? Context helps determine if the response variable simply varies a lot. (e.g., stocks) How do we incorporate categorical predictors? In our housing dataset, there is a Heat.Type that indicates whether the heating type of the house is of type 2, 3, or 4. Including a categorical predictor variable creates \\(L-1\\) indicator variables where \\(L\\) is the number of levels of the categorical variable. Type 2 is chosen as the reference category by default in R because it is first in alphanumeric order. Heat.Type3 and Heat.Type4 get created as indicator variables by taking the original variable name (Heat.Type) and pasting the name of the category (3 or 4 afterward) Heat.Type3 equals 1 is this case is of heating type 3. Equals 0 otherwise. Heat.Type4 equals 1 is this case is of heating type 4. Equals 0 otherwise. Case Heat.Type Heat.Type3 Heat.Type4 ---- --------- ---------- ---------- 1 3 1 0 2 4 0 1 3 4 0 1 4 2 0 0 mod2 &lt;- lm(Price ~ Heat.Type, data = homes) summary(mod2) ## ## Call: ## lm(formula = Price ~ Heat.Type, data = homes) ## ## Residuals: ## Min 1Q Median 3Q Max ## -221355 -63355 -17644 43895 548645 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 226355 2853 79.348 &lt; 2e-16 *** ## Heat.Type3 -17223 6192 -2.781 0.00547 ** ## Heat.Type4 -64467 6168 -10.451 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 95510 on 1725 degrees of freedom ## Multiple R-squared: 0.05972, Adjusted R-squared: 0.05863 ## F-statistic: 54.78 on 2 and 1725 DF, p-value: &lt; 2.2e-16 From this output, I can see that the regression model formula is: \\[ \\begin{align*} E[\\hbox{Price}] &amp;= \\beta_0 + \\beta_1\\,\\hbox{Heat.Type3} + \\beta_2\\,\\hbox{Heat.Type4} \\\\ &amp;= 226355 - 17223\\,\\hbox{Heat.Type3} - 64467\\,\\hbox{Heat.Type4} \\end{align*} \\] When a house is of heating type 2, what are the values of the indicator variables? Thus what is the expected (average) price for a house of heating type 2? Same questions for types 3 and 4 This leads us to the interpretation of the coefficients in this model. Exercises We won’t be working in R today. Instead, look at the output from R code below, and answer the following questions. Exercise 1 Let’s look at a model that describes Price in terms of Fuel.Type, which can be of types 2, 3, or 4. mod3 &lt;- lm(Price ~ Fuel.Type, data = homes) summary(mod3) ## ## Call: ## lm(formula = Price ~ Fuel.Type, data = homes) ## ## Residuals: ## Min 1Q Median 3Q Max ## -223535 -60535 -19652 42811 546465 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 228535 2748 83.160 &lt; 2e-16 *** ## Fuel.Type3 -63598 6021 -10.563 &lt; 2e-16 *** ## Fuel.Type4 -39801 7029 -5.663 1.74e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 95080 on 1725 degrees of freedom ## Multiple R-squared: 0.06823, Adjusted R-squared: 0.06715 ## F-statistic: 63.16 on 2 and 1725 DF, p-value: &lt; 2.2e-16 Interpret all coefficients in this model. Interpret the \\(R^2\\) and residual standard error to evaluate the quality of the model. What is the residual for a $250,000 house that is of fuel type 2? What about a $250,000 house that is of fuel type 3? Exercise 2 Let’s look at a model that describes Price in terms of Sewer.Type, which can be of types 1, 2, or 3. mod4 &lt;- lm(Price ~ Sewer.Type, data = homes) summary(mod4) ## ## Call: ## lm(formula = Price ~ Sewer.Type, data = homes) ## ## Residuals: ## Min 1Q Median 3Q Max ## -211426 -66426 -21426 45574 574716 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 250952 28340 8.855 &lt;2e-16 *** ## Sewer.Type2 -50668 28676 -1.767 0.0774 . ## Sewer.Type3 -34527 28479 -1.212 0.2255 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 98170 on 1725 degrees of freedom ## Multiple R-squared: 0.006633, Adjusted R-squared: 0.005481 ## F-statistic: 5.759 on 2 and 1725 DF, p-value: 0.003215 Interpret all coefficients in this model. Interpret the \\(R^2\\) and residual standard error to evaluate the quality of the model. What is the residual for a $200,000 house that is of sewer type 3? What about a $200,000 house that is of sewer type 1? "],["multiple-linear-regression.html", "Topic 7 Multiple Linear Regression Learning Goals Discussion and Exercises", " Topic 7 Multiple Linear Regression Learning Goals Understand the predictive and causal viewpoints for including multiple predictor variables in regression models Interpret the coefficients in multiple linear regression models Graphically/geometrically describe the “pictures” implied by different multivariate models Understand how to extend linear regression models with polynomial terms to model nonlinear relationships Discussion and Exercises A template RMarkdown document that you can start from is available here. New data context: diamond prices library(readr) library(ggplot2) library(dplyr) diamonds &lt;- read_csv(&quot;https://www.dropbox.com/s/9c8jqda4pwaq8i1/diamonds.csv?dl=1&quot;) Research question: How are different factors related to the price of a diamond? Let’s familiarize ourselves with the data: # Display the dimensions and first few rows Key variables: carat: the weight of the diamond in carats (1 carat = 200 milligrams) price: price in US dollars cut: quality of the cut of the diamond (Fair, Good, Very Good, Premium, Ideal) color: Level 1 (best) to Level 7 (worst) clarity: Level 1 (worst) to Level 8 (best) x, y, and z: length, width, and depth respectively (in mm) depth: total depth percentage = z / mean(x, y) table: width of top of diamond relative to widest point Exercise 1: What are your expectations for how price and clarity will be related? Construct a visualization to see. (Clarity level 1 is deemed worst and level 8 is deemed best.) # Plot of price vs. clarity Exercise 2: Let’s first fit a linear regression model with just clarity as a predictor of price. mod1 &lt;- lm(price ~ clarity, data = diamonds) summary(mod1) Why is there no coefficient for clarityLevel_1? Interpret the clarityLevel_2 and clarityLevel_5 coefficients. Based on this output, can you tell which clarity level has the highest mean price in this dataset? Explain. Relate the magnitudes of the coefficients to the trends that you see in your plot. Exercise 3: What if the most clear diamonds happened to be quite small (low carat)? Would this explain why your plot looks the way it does? We can picture the relationship between clarity, carat, and price with a causal diagram. Exercise 3 is getting us to think about carat being a confounding variable in the relationship between clarity and price. A confounding variable is a cause of both the variable of interest (clarity) and of the response variable (price): carat being a cause of clarity tells us that there is potential for the most clear diamonds to be of systematically different sizes (likely smaller) than less clear diamonds. This idea with the fact that carat is a cause of price leads to the initially misleading relationship between clarity and price. Wouldn’t it be nice if we could hold carat fixed and then compare diamonds of different clarity? We can with regression models. If we want to examine average changes in the response while letting one variable change and holding the others fixed, we can add those other variables to the model: \\[ E[\\hbox{price}] = \\beta_0 + \\beta_1\\hbox{clarityLevel_2} + \\beta_2\\hbox{clarityLevel_3} + \\cdots + \\beta_7\\hbox{clarityLevel_8} + \\beta_8\\hbox{carat} \\] Let’s simplify this model to gain better understanding: For clarity level 1: \\[ E[\\hbox{price}] = \\beta_0 + \\beta_8\\hbox{carat} \\] \\(\\beta_0\\) is the intercept \\(\\beta_8\\) is the carat coefficient (the slope for carat) For clarity level 2: \\[ \\begin{align*} E[\\hbox{price}] &amp;= \\beta_0 + \\beta_1 \\times 1 + \\beta_8\\hbox{carat} \\\\ &amp;= (\\beta_0 + \\beta_1) + \\beta_8\\hbox{carat} \\end{align*} \\] \\(\\beta_0+\\beta_1\\) is the intercept \\(\\beta_8\\) is the carat coefficient (the slope for carat) For clarity level 8: \\[ \\begin{align*} E[\\hbox{price}] &amp;= \\beta_0 + \\beta_7 \\times 1 + \\beta_8\\hbox{carat} \\\\ &amp;= (\\beta_0 + \\beta_7) + \\beta_8\\hbox{carat} \\end{align*} \\] \\(\\beta_0+\\beta_7\\) is the intercept \\(\\beta_8\\) is the carat coefficient (the slope for carat) Observations about these clarity level-specific model formulas: The carat coefficient is always the same: \\(\\beta_8\\) The intercept changes for each level of clarity \\(\\beta_1\\) to \\(\\beta_7\\) indicate changes in the intercept, compared to the reference category: clarity level 1 This model (y ~ categorical+quantitative) is called a parallel lines model. Exercise 4: Add to your previous model by including carat as a predictor. mod2 &lt;- lm(price ~ clarity+carat, data = diamonds) summary(mod2) Write an expression for the average price of a clarity level 1 diamond that is zero carats. What coefficient does this allow you to interpret? Write an expression for the average price of a clarity level 1 diamond that is \\(C\\) carats. Write an expression for the average price of a clarity level 2 diamond that is \\(C\\) carats. Subtract your answer from part (b) from this expression. Based on this, give an interpretation of the clarityLevel_2 coefficient. Write an expression for the average price of a clarity level 3 diamond that is \\(C\\) carats. Subtract your answer from part (b) from this expression. Based on this, give an interpretation of the clarityLevel_3 coefficient. Pick any clarity level. Write an expression for the average price of two diamonds of that clarity level: (1) one with \\(C\\) carats and (2) one with \\(C+1\\) carats. Subtract (1) from (2), and thus interpret the carat coefficient. Compare the values of the clarityLevel coefficients in mod2 and mod1 and form a conclusion about the relationship between price and clarity. In general, a linear regression model with multiple predictors is called a multiple linear regression model. \\[ E[y] = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_p x_p \\] Interpreting \\(\\beta_1\\): Case 1: \\(x_1 = a_1, \\qquad x_2 = a_2, \\ldots, x_p = a_p\\) \\[ E[y_1] = \\beta_0 + \\beta_1 a_1 + \\beta_2 a_2 + \\cdots + \\beta_p a_p \\] Case 2: \\(x_1 = a_1 + 1, x_2 = a_2, \\ldots, x_p = a_p\\) Value of \\(x_1\\) is 1 unit higher, but otherwise exactly the same as Case 1. \\[ E[y_2] = \\beta_0 + \\beta_1 (a_1+1) + \\beta_2 a_2 + \\cdots + \\beta_p a_p \\] We can compare the expected (average) response for case 1 and case 2: \\[ E[y_2] - E[y_1] = \\beta_1 \\] Thus, \\(\\beta_1\\) is the expected change in the response for every unit change in the predictor \\(x_1\\), holding constant the other predictors in the model. On average, if we increase \\(x_1\\) by 1, we expect the response to change by \\(\\beta_1\\), holding constant the other predictors in the model. General strategy for interpreting regression coefficients Interpreting a coefficient on a quantiative variable \\(x\\) Write an expression for the expected outcome for (1) a case that has \\(x = a\\) and (2) a case that has \\(x = a+1\\) Make all other predictors have the same value for the two cases Compare the expected outcomes for the two cases to interpret the coefficient Interpreting a coefficient for an indicator variable for a categorical variable \\(x\\) Write an expression for the expected outcome for (1) a case that has \\(x\\) equal to the reference category and (2) a case that has \\(x\\) equal to the category of interest (the one corresponding to the coefficient) Make all other predictors have the same value for the two cases Compare the expected outcomes for the two cases to interpret the coefficient Exercise 5: What are we assuming about the form of the relationship between price and carat by including it in the model mod2? Make an appropriate plot to check. (Make sure to add + geom_smooth() to your plot.) Exercise 6: We can model nonlinear trends with linear regression models by adding polynomial terms. The code below fits the model \\[ E[\\hbox{price}] = \\beta_0 + \\beta_1\\hbox{clarityLevel_2} + \\cdots + \\beta_7\\hbox{clarityLevel_8} + \\beta_8\\hbox{carat} + \\beta_9\\hbox{carat}^2 \\] mod3 &lt;- lm(price ~ clarity + poly(carat, degree = 2, raw = TRUE), data = diamonds) summary(mod3) The coefficients poly(carat, degree = 2, raw = TRUE)1 and poly(carat, degree = 2, raw = TRUE)2 represent \\(\\beta_8\\) and \\(\\beta_9\\) respectively and aren’t really interpretable anymore. But the clarityLevel coefficients still have the same interpretation as in mod2. Do you reach the same conclusions about the relationship between clarity and price here as in mod2? How does the residual standard error compare in mod2 and mod3 and what does this indicate about the quality of the two models? (We can’t compare the Multiple R-squared, but we can compare the Adjusted R-squared. Coming up later!) Exercise 7: Now let’s consider color (Level 1 is best, and Level 7 is worst.) What do you expect the relationship between color and price to be. Make a plot to check. Fit a multiple linear regression model of price with clarity, carat, and color (Level 1 is best, and Level 7 is worst.) Interpret the intercept, clarityLevel_2, carat, and colorLevel_2 coefficients. If the intercept is not meaningful, what could we do to make it meaningful? For carat to confound the relationship between color and price, what two properties must it have? Contextually, do you think that is plausible? Make plots to check if the data support that hypothesis. Do the same for carat confounding the relationship between clarity and price. Write a few sentences summarizing the nature of the confounding role of carat in the clarity vs. price and color vs. price relationships. Exercise 8: (Extra practice if you have time.) Fit a multiple linear regression model of price with clarity, carat, color, and cut. Interpret the intercept, clarityLevel_2, carat, colorLevel_2, and cut2_Good coefficients. Summarize your overall findings from this model, and appropriately compare its quality to the previous models. "],["interaction-models.html", "Topic 8 Interaction Models Learning Goals Discussion and Exercises", " Topic 8 Interaction Models Learning Goals Understand what research questions can be answered with interaction models Interpret coefficients in interaction models Connect visualizations to the coefficient estimates in interaction models Graphically/geometrically describe the “pictures” implied by different types of interaction models Discussion and Exercises A template RMarkdown document that you can start from is available here. We will continue looking at the diamonds dataset. carat: the weight of the diamond in carats (1 carat = 200 milligrams) price: price in US dollars cut: quality of the cut of the diamond (Fair, Good, Very Good, Premium, Ideal) color: Level 1 (best) to Level 7 (worst) clarity: Level 1 (worst) to Level 8 (best) x, y, and z: length, width, and depth respectively (in mm) depth: total depth percentage = z / mean(x, y) table: width of top of diamond relative to widest point library(readr) library(ggplot2) library(dplyr) diamonds &lt;- read_csv(&quot;https://www.dropbox.com/s/9c8jqda4pwaq8i1/diamonds.csv?dl=1&quot;) Warm-up: Consider the model of price as a function of clarity and carat. \\[ E[\\hbox{price}] = \\beta_0 + \\beta_1\\hbox{clarityLevel_2} + \\beta_2\\hbox{clarityLevel_3} + \\cdots + \\beta_7\\hbox{clarityLevel_8} + \\beta_8\\hbox{carat} \\] Why was this called a parallel lines model? Draw a picture of the relationships that this model implies and label the picture with the coefficients of the model. Exercise 1: We looked at a scatterplot of price versus carat and boxplots of price versus clarity, but we haven’t looked at all three variables simultaneously. Let’s enrich the scatterplot to additionally show clarity. We’ve seen that we can have x, y, color, and fill aesthetics (inside the aes()). How might we adapt the code below to show different color trend lines corresponding to the 8 clarity levels? ggplot(diamonds, aes(x = carat, y = price)) + geom_point() + geom_smooth() If the relationship between the response \\(y\\) and predictor \\(x_1\\) differs depending on the value / categories of another predictor \\(x_2\\), we say that \\(x_1\\) and \\(x_2\\) interact. We capture this in our models with an interaction term: \\(x_1 \\times x_2\\). \\[ E[y] = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_1 \\times x_2 \\] The coefficient \\(\\beta_3\\) in front of the interaction term is called the interaction coefficient. For now, let’s work with a subset of the data that just has two clarity levels. \\[ E[\\hbox{price}] = \\beta_0 + \\beta_1\\hbox{clarity2} + \\beta_2\\hbox{carat} + \\beta_3\\hbox{clarity2}\\times\\hbox{carat} \\] diamonds_sub &lt;- diamonds %&gt;% filter(clarity %in% c(&quot;Level_1&quot;, &quot;Level_2&quot;)) mod1 &lt;- lm(price ~ clarity*carat, data = diamonds_sub) summary(mod1) ## ## Call: ## lm(formula = price ~ clarity * carat, data = diamonds_sub) ## ## Residuals: ## Min 1Q Median 3Q Max ## -6051.1 -645.7 -112.8 485.6 6304.1 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1480.56 103.76 -14.27 &lt;2e-16 *** ## clarityLevel_2 -1937.78 108.04 -17.94 &lt;2e-16 *** ## carat 4209.79 72.51 58.06 &lt;2e-16 *** ## clarityLevel_2:carat 3660.46 76.76 47.69 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1247 on 9931 degrees of freedom ## Multiple R-squared: 0.911, Adjusted R-squared: 0.9109 ## F-statistic: 3.387e+04 on 3 and 9931 DF, p-value: &lt; 2.2e-16 Note: When you see a colon between two variables, the colon means a multiplication sign. (clarityLevel_2:carat is the product of the clarityLevel_2 indicator variable and the carat variable.) Model formula \\[ \\begin{align*} E[\\hbox{price}] &amp;= \\beta_0 + \\beta_1\\hbox{clarity2} + \\beta_2\\hbox{carat} + \\beta_3\\hbox{clarity2}\\times\\hbox{carat} \\\\ &amp;= -1480.56 - 1937.78\\,\\hbox{clarity2} + 4209.79\\,\\hbox{carat} + 3660.46\\,\\hbox{clarity2}\\times\\hbox{carat} \\end{align*} \\] Model formula for clarity level 1 \\[ \\begin{align*} E[\\hbox{price}] &amp;= -1480.56 - 1937.78\\times 0 + 4209.79\\,\\hbox{carat} + 3660.46\\times 0 \\times\\hbox{carat} \\\\ &amp;= -1480.56 + 4209.79\\,\\hbox{carat} \\end{align*} \\] Model formula for clarity level 2 \\[ \\begin{align*} E[\\hbox{price}] &amp;= -1480.56 - 1937.78\\times 1 + 4209.79\\,\\hbox{carat} + 3660.46\\times 1 \\times\\hbox{carat} \\\\ &amp;= (-1480.56 - 1937.78) + (4209.79 + 3660.46)\\,\\hbox{carat} \\\\ &amp;= -3418.34 + 7870.25\\,\\hbox{carat} \\end{align*} \\] It is very helpful to draw a picture labeled with the coefficients. Coefficient interpretations: Intercept \\(\\beta_0\\): -1480.56 The average price for a zero carat, level 1 clarity diamond. (Could have made more meaningful by centering carat, but generally not interested in the intercept.) \\(\\beta_2\\) for carat: 4209.79 The slope for the clarity level 1 model. On average, diamond price increases by $4209.79 per carat increase in level 1 clarity diamonds. (This rate of change is different for clarity level 2 diamonds.) \\(\\beta_1\\) for clarityLevel_2: -1937.78 The change in y-intercept going from clarity level 1 to 2. On average, zero carat diamonds that are clarity level 2 are worth $1937.78 less than zero carat, clarity level 1 diamonds. \\(\\beta_3\\) for the interaction term (clarityLevel_2:carat): 3660.46 The change in slope for the clarity level 2 vs. the clarity level 1 model. The average change in price per carat increase is 3660.46 ($/carat) higher for clarity level 2 vs. clarity level 1 diamonds. The slope is steeper for level 2. A carat is worth more for a level 2 clarity diamond. Exercise 2: Fit a model with interaction between clarity and carat for the full diamonds dataset. Write out the model formulas for clarity level 1, 2, … diamonds until you get the hang of it. Draw a picture with the model lines for clarity level 1, 2, … 8 diamonds. Annotate this picture with the model coefficients. Interpret the clarityLevel_3 and clarityLevel_3:carat coefficients. Repeat for level 4 and onwards until you get the hang of it. For which clarity level is a carat worth the most? How much is a carat worth on average? Exercise 3: Now let’s consider diamond color (Level 1 is best and Level 7 is worst). What research question are you exploring when you fit a model with interaction between color and carat? Generalize this to a broader context. Make a plot that allows you to explore potential interaction between color and carat. What are you looking to see in the plot? Do you think an interaction model is appropriate? Fit the interaction model, and focus on the coefficients of substantive interest. Summarize your overall conclusions. The remainder of these exercises don’t require R. Exercise 4: We’ve seen interaction between a categorical and a quantitative variable. Two categorical variables can interact as well. Consider the model \\[ \\begin{align*} E[\\hbox{winpercent}] = \\beta_0 &amp;+ \\beta_1\\hbox{chocolateTRUE} \\\\ &amp;+ \\beta_2\\hbox{peanutyalmondyTRUE} + \\beta_3\\hbox{chocolateTRUE}\\times\\hbox{peanutyalmondyTRUE} \\end{align*} \\] Write out the model formulas for the non-chocolate candies and for the chocolate candies. Leave peanutyalmondyTRUE as-is without plugging in anything for it. (Similar to leaving carat as-is in the diamonds context.) From part (a), interpret \\(\\beta_0\\) and \\(\\beta_2\\). Then interpret \\(\\beta_0+\\beta_1\\) and \\(\\beta_2+\\beta_3\\). The mean winpercents in all four combinations of chocolate and peanutyalmondy are shown below. From this information, determine the values of the model coefficients. candy %&gt;% dplyr::group_by(chocolate, peanutyalmondy) %&gt;% summarize(mean_winpercent = mean(winpercent)) ## `summarise()` has grouped output by &#39;chocolate&#39;. You can override using the `.groups` argument. ## # A tibble: 4 x 3 ## # Groups: chocolate [2] ## chocolate peanutyalmondy mean_winpercent ## &lt;lgl&gt; &lt;lgl&gt; &lt;dbl&gt; ## 1 FALSE FALSE 42.5 ## 2 FALSE TRUE 34.9 ## 3 TRUE FALSE 57.3 ## 4 TRUE TRUE 68.5 Now interpret \\(\\beta_0\\), \\(\\beta_2\\), \\(\\beta_0+\\beta_1\\), and \\(\\beta_2+\\beta_3\\) in a contextually meaningful way. Is nuttiness (peanutyalmondy) “better” in chocolate candies or in non-chocolate candies? Exercise 5: Two quantitative variables can interact as well. In a model of Price, the Mileage and Age of a used car interact: the relationship between mileage and price differs depending upon the age of the car. Below, the yellow lines represent the relationship between price and mileage for 1 year old, 5 year old, and 10 year old used cars. Based on this plot, what do you anticipate about the signs of the coefficients in the interaction model? (Don’t look ahead to the output below yet.) \\[ E[\\hbox{Price}] = \\beta_0 + \\beta_1 \\hbox{Age} + \\beta_2 \\hbox{Mileage} + \\beta_3 \\hbox{Age}\\times\\hbox{Mileage} \\] Based on the model output below, write the model formulas relating Price to Mileage for cars that are 0 years (new), 5 years, and 12 years old. fords &lt;- read_csv(&quot;https://www.dropbox.com/s/wmb6ktyaw5c5jwf/Fords.csv?dl=1&quot;) fords_mod &lt;- lm(Price ~ Age*Mileage, data = fords) summary(fords_mod) ## ## Call: ## lm(formula = Price ~ Age * Mileage, data = fords) ## ## Residuals: ## Min 1Q Median 3Q Max ## -6950.1 -1254.4 -35.5 1124.6 7355.2 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.932e+04 2.256e+02 85.65 &lt;2e-16 *** ## Age -1.523e+03 6.042e+01 -25.21 &lt;2e-16 *** ## Mileage -1.349e-01 4.835e-03 -27.91 &lt;2e-16 *** ## Age:Mileage 1.320e-02 6.488e-04 20.34 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1899 on 606 degrees of freedom ## (25 observations deleted due to missingness) ## Multiple R-squared: 0.8342, Adjusted R-squared: 0.8334 ## F-statistic: 1016 on 3 and 606 DF, p-value: &lt; 2.2e-16 Given (b), what does the interaction coefficient help us learn about the relationship between Price and Mileage? Extra (not required but good practice): Interpret each of the coefficients in the above model. Interlude: Take a moment to think about the theme of these interaction exercises. In all of them, we have used interaction terms to describe how the relationship between a variable and the response is modified by the value of another variable. For this reason, interaction is also called effect modification. Diamond clarity and color modify the effect of size on price. Note that effect modification/interaction is symmetric, so we can also say that diamond size modifies the effect of clarity and color on price. However, usually with interaction between a quantitative and a categorical variable, we describe it in the first way. Chocolatiness modifies the effect of nuttiness on candy popularity. Symmetrically, nuttiness modifies the effect of chocolatiness on candy popularity. Car age modifies the effect of mileage on price. Symmetrically, mileage modifies the effect of care age on its price. Exercise 6: Confounding and interaction are not the same idea. Draw or describe how the situation below could arise: carat does confound the relationship between clarity and price. There is no interaction between carat and clarity. Draw or describe how the situation below could arise: carat does not confound the relationship between clarity and price. There is interaction between carat and clarity. "],["redundancy-multicollinearity-and-adjusted-r-squared.html", "Topic 9 Redundancy, Multicollinearity, and Adjusted R-squared Learning Goals Discussion", " Topic 9 Redundancy, Multicollinearity, and Adjusted R-squared Learning Goals Explain when variables are redundant or multicollinear Relate redundancy and multicollinearity to coefficient estimates and \\(R^2\\) Explain why adjusted \\(R^2\\) is preferable to multiple \\(R^2\\) when comparing models with different numbers of predictors Discussion A reminder of why we care about all of this… By the end of the flight, he had made several requests, initiated several times, &amp; his behaviors had reduced quite a bit. The father was astounded – clearly no one had ever tried an AAC approach with him. I gave him the paper &amp; showed him how to use it, and he nearly cried. 6/ — Rachel R. Romeo (@RachelRRomeo) August 28, 2019 Models help us make useful comparisons. Why are multiple regression models so useful? Adding predictors to models… Predictive viewpoint: Helps us better predict the response Descriptive viewpoint: Helps us better understand the isolated (causal) effect of a variable by holding constant confounders BUT we can’t throw in predictors indiscriminately. Context: Measuring body fat accurately is difficult. It would be nice to be able We have a dataset of physical measurements on males (height, neck, thigh, etc.) Below we create an inches version of the abdomen variable: bodyfat &lt;- bodyfat %&gt;% mutate(abdomenInches = abdomen/2.54) Consider the following 3 models. What do you think the Multiple \\(R^2\\) values will look like? mod1 &lt;- lm(fat ~ abdomen, data = bodyfat) mod2 &lt;- lm(fat ~ abdomenInches, data = bodyfat) mod3 &lt;- lm(fat ~ abdomen+abdomenInches, data = bodyfat) summary(mod1)$r.squared ## [1] 0.6616721 summary(mod2)$r.squared ## [1] 0.6616721 summary(mod3)$r.squared ## [1] 0.6616721 They’re all the same! This is because abdomen and abdomenInches are redundant. They contain exactly the same information and predict each other in a perfect line: Let’s look at the summary output for mod3: summary(mod3) ## ## Call: ## lm(formula = fat ~ abdomen + abdomenInches, data = bodyfat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -19.0160 -3.7557 0.0554 3.4215 12.9007 ## ## Coefficients: (1 not defined because of singularities) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -39.28018 2.66034 -14.77 &lt;2e-16 *** ## abdomen 0.63130 0.02855 22.11 &lt;2e-16 *** ## abdomenInches NA NA NA NA ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.877 on 250 degrees of freedom ## Multiple R-squared: 0.6617, Adjusted R-squared: 0.6603 ## F-statistic: 488.9 on 1 and 250 DF, p-value: &lt; 2.2e-16 Question: The NA’s for the abdomenInches coefficient can be read as “cannot be computed”. Why do you think that is? The dataset also contains a hip variable giving hip circumference in centimeters. Consider the following 3 models: mod1: fat ~ abdomen (R-squared = 0.66) mod4: fat ~ hip (R-squared = 0.39) mod5: fat ~ abdomen + hip What do you think the R-squared for mod5 will be? Close to 1 Close to 0.66 Close to 0.39 Midway from 0.66 to 1 Abdomen and hip circumference are not perfectly linearly related but they are very similar. For this reason, we describe abdomen and hip as being multicollinear. summary(mod5) ## ## Call: ## lm(formula = fat ~ abdomen + hip, data = bodyfat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -12.4170 -3.4849 -0.2697 3.1331 12.6522 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -19.68017 4.65242 -4.230 3.28e-05 *** ## abdomen 0.87790 0.05611 15.647 &lt; 2e-16 *** ## hip -0.42464 0.08445 -5.028 9.47e-07 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.657 on 249 degrees of freedom ## Multiple R-squared: 0.6929, Adjusted R-squared: 0.6904 ## F-statistic: 280.9 on 2 and 249 DF, p-value: &lt; 2.2e-16 Question: How can we interpret the hip coefficient in mod5? Does this makes sense? Takeaway messages: redundancy and multicollinearity Adding a redundant predictor to a model… Does nothing to the \\(R^2\\) Results in a senseless coefficient (that cannot even be estimated) Adding a multicollinear predictor to a model… Minimally increases the \\(R^2\\) Creates some concern over the interpretability of the coefficients What’s wrong with the multiple R-squared? Adding a multicollinear predictor minimally increases \\(R^2\\) but what about a useless predictor? For illustration purposes, we’ll look at a random sample of 10 of the males from the dataset: bodyfat_subs &lt;- bodyfat %&gt;% sample_n(10) Let’s see if we can get our \\(R^2\\) up to 1! great_model &lt;- lm(fat ~ abdomen+hip+thigh+knee+ankle+biceps+forearm+wrist, data = bodyfat_subs) summary(great_model) ## ## Call: ## lm(formula = fat ~ abdomen + hip + thigh + knee + ankle + biceps + ## forearm + wrist, data = bodyfat_subs) ## ## Residuals: ## 1 2 3 4 5 6 7 8 9 10 ## 1.6847 1.1226 -2.1510 -0.5134 -6.0221 -0.5407 -0.5896 -0.3084 0.2276 7.0903 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 81.3987 337.6274 0.241 0.849 ## abdomen -3.8043 8.8751 -0.429 0.742 ## hip 1.7024 5.4926 0.310 0.809 ## thigh 5.3014 13.6454 0.389 0.764 ## knee -0.4697 7.4011 -0.063 0.960 ## ankle -23.1111 46.1612 -0.501 0.704 ## biceps 2.1005 8.8396 0.238 0.851 ## forearm 1.7760 2.8428 0.625 0.645 ## wrist 12.8804 28.3614 0.454 0.729 ## ## Residual standard error: 9.814 on 1 degrees of freedom ## Multiple R-squared: 0.8273, Adjusted R-squared: -0.5542 ## F-statistic: 0.5988 on 8 and 1 DF, p-value: 0.7677 Darn! We probably just needed the magic predictor! Let’s make it… bodyfat_subs &lt;- bodyfat_subs %&gt;% mutate(magic = c(1,2,3,4,5,6,7,8,9,10)) …and fit the model: best_model &lt;- lm(fat ~ abdomen+hip+thigh+knee+ankle+biceps+forearm+wrist+magic, data = bodyfat_subs) summary(best_model) ## ## Call: ## lm(formula = fat ~ abdomen + hip + thigh + knee + ankle + biceps + ## forearm + wrist + magic, data = bodyfat_subs) ## ## Residuals: ## ALL 10 residuals are 0: no residual degrees of freedom! ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -218.0921 NA NA NA ## abdomen 3.5342 NA NA NA ## hip 2.1323 NA NA NA ## thigh -4.0071 NA NA NA ## knee -6.9763 NA NA NA ## ankle 11.0245 NA NA NA ## biceps -5.0921 NA NA NA ## forearm 3.6325 NA NA NA ## wrist -0.1533 NA NA NA ## magic 3.3883 NA NA NA ## ## Residual standard error: NaN on 0 degrees of freedom ## Multiple R-squared: 1, Adjusted R-squared: NaN ## F-statistic: NaN on 9 and 0 DF, p-value: NA The multiple R-squared always goes up when a non-redundant variable is added to a model, even if that predictor is useless! For this reason, using the multiple R-squared to compare models with different numbers of predictors is not fair. It is better to use adjusted R-squared: \\[ \\hbox{Adj } R^2 = 1 - (1-R^2)\\frac{n-1}{n-p-1} = R^2 - \\hbox{penalty} \\] \\(n\\) is the sample size, and \\(p\\) is the number of non-intercept coefficients. Key takeaway: The magnitude of the penalty increases as the number of predictors increases. So the adjusted R-squared won’t increase unless the predictor increases the multiple R-squared sufficiently to surpass this penalty. Adjusted R-squared allows us to fairly compare the predictive ability of models with different numbers of predictors. We have to take care when using polynomial terms to model nonlinearity: poly_mod1 &lt;- lm(fat ~ abdomen, data = bodyfat_subs) poly_mod2 &lt;- lm(fat ~ poly(abdomen, degree=2, raw=TRUE), data = bodyfat_subs) poly_mod3 &lt;- lm(fat ~ poly(abdomen, degree=3, raw=TRUE), data = bodyfat_subs) poly_mod4 &lt;- lm(fat ~ poly(abdomen, degree=4, raw=TRUE), data = bodyfat_subs) poly_mod5 &lt;- lm(fat ~ poly(abdomen, degree=5, raw=TRUE), data = bodyfat_subs) Degree 1: Multiple \\(R^2\\) = 0.4596936. Adjusted \\(R^2\\) = 0.3921553. Degree 2: Multiple \\(R^2\\) = 0.5835658. Adjusted \\(R^2\\) = 0.4645846. Degree 3: Multiple \\(R^2\\) = 0.5839466. Adjusted \\(R^2\\) = 0.3759198. Degree 4: Multiple \\(R^2\\) = 0.6612701. Adjusted \\(R^2\\) = 0.3902862. Degree 5: Multiple \\(R^2\\) = 0.6899167. Adjusted \\(R^2\\) = 0.3023125. This phenomenon of fitting the data too closely is called overfitting. If you’re interested in learning how to build models for purely predictive (not descriptive) purposes, take Statistical Machine Learning! "],["review.html", "Topic 10 Review Task", " Topic 10 Review Task Get to know your new group mates. Share your preferred pronouns, year in school, majors, minors, hobbies, and anything else important to you. Together, create one Google Doc that you will work on together (to be shared with the instructor). This document will be a strategy guide to correctly using regression models. In it, you should do the following: For all types of linear regression models we’ve discussed, what are the general interpretations of the coefficients? What research questions do these models try to answer? Simple linear regression models with one quantitative or one categorical predictor Multiple regression models (no interaction) with a mix of quantitative and categorical predictors Interaction models with an interaction between (1) one quantitative and one categorical variable, (2) two categorical variables, (3) two quantitative variables. (Only two predictors in these models, and they were both involved in the interaction.) Write a quiz question that tests the concept of confounding. Make up a data example and provide the solution to the question. Write a quiz question that tests the concept of interaction. Make up a data example and provide the solution to the question. You’ll get feedback on this group work. "],["experiment.html", "Topic 11 Experiment! Motivation Experiment Analysis and Discussion", " Topic 11 Experiment! Motivation When you drive, bike, or walk (or commute in some other way), you need to be able to react quickly to avoid various hazards. How much can distraction affect your reaction times? Choice: Use distracting music that your instructor found OR have loud, distracting conversations where you intentionally try to distract your classmates? Experiment Part 1: Random assignment Pick two group members at each table. Randomly assign these two group members to the Treatment or the Control group by rolling the die: Even: Treatment (loud distractions) Odd: Control (complete quiet in the room) The other group members will be in the opposite group. Quiet phase first! For those in the Control group, go to: https://www.humanbenchmark.com/tests/reactiontime/ Read the instructions, and click to start the trial. Record the reaction time from the first trial here. Noisy phase! For those in the Treatment group, go to: https://www.humanbenchmark.com/tests/reactiontime/ Read the instructions, and click to start the trial. Record the reaction time from the first trial here. Analysis and Discussion A template RMarkdown document that you can start from is available here. library(readr) library(ggplot2) library(dplyr) experiment &lt;- read_csv(&quot;https://www.dropbox.com/s/cwhhr0vjibw64tx/experiment_spring_2020.csv?dl=1&quot;) A little bit of data management (cleaning): colnames(experiment) &lt;- c(&quot;timestamp&quot;, &quot;arm&quot;, &quot;rtime&quot;, &quot;vid_games&quot;, &quot;sports&quot;, &quot;drive&quot;, &quot;hand&quot;) Part 1: Comparing the groups We can calculate the observed difference in mean reaction time between the treatment and conrol groups: # Use the pipe %&gt;% to chain together a series of commands # First: group the data by experiment arm (treatment and control) # Second: compute the mean reaction time in each arm experiment_summ &lt;- experiment %&gt;% group_by(arm) %&gt;% summarize(mean_rtime = mean(rtime)) # Display the data summary experiment_summ # Observed difference in means experiment_summ$mean_rtime[2] - experiment_summ$mean_rtime[1] Fit a linear regression model that would also give this result, and display the summary output: experiment_mod &lt;- lm(???) Part 2: Is this a real difference? We performed this experiment on a sample of people at Macalester, but we conducted our study in the hopes of understanding a result in a broader population. Question for thought: How different would our data (and results) look if we had used a different sample of people? We often don’t have the luxury (or resources) to get many different samples. Let’s instead resample our own data to get an answer to that question. # Sample size of the experiment n &lt;- nrow(experiment) # How many times will we resample? num_resamples &lt;- 1000 # Resample the data and estimate the difference resampled_coeffs &lt;- replicate(num_resamples, { experiment_resampled &lt;- experiment %&gt;% sample_n(size = n, replace = TRUE) mod &lt;- lm(rtime ~ arm, data = experiment_resampled) coefficients(mod)[&quot;armTreatment&quot;] }) # Look at the first few resampled coefficients head(resampled_coeffs) # Put the resampled coefficients into a dataset and plot data_resampled &lt;- data.frame(coefficients = resampled_coeffs) ggplot(data_resampled, aes(x = coefficients)) + geom_histogram() What information does this histogram give you? Is there evidence for a real difference in the broader population of adults? This procedure of resampling the data and estimating a quantity of interest is called bootstrapping. Can you think of how this procedure might be of general use for us? Part 3: Study design Are the treatment and control groups similar in every respect except the distraction? Were the classroom conditions exactly the same for both groups? Make plots to check if the groups were similar in their video game playing, sports participation, driving frequency, and handedness. How might you improve the design of the experiment? What is the importance of the random assignment to the treatment or control group? What might be a concern if people were allowed to self-select into the treatment or control group? Draw a causal diagram to describe this (similar to the diagrams we’ve drawn for confounding). "],["bootstrapping.html", "Topic 12 Bootstrapping Learning Goals Discussion Exercises", " Topic 12 Bootstrapping Learning Goals Explain the idea of the true population value for a quantity Describe the steps and assumptions of the bootstrapping procedure and how it estimates sampling variation Use bootstrap confidence intervals to answer research questions Discussion Research question: What is the causal effect of loud distractions on reaction times? More on the “causal” part next time. But for now, we will express “causal” as meaning: there is no influence of confounding variables. Is this true? (You’ll check in the exercises.) original_model &lt;- lm(rtime ~ arm, data = experiment) summary(original_model) ## ## Call: ## lm(formula = rtime ~ arm, data = experiment) ## ## Residuals: ## Min 1Q Median 3Q Max ## -117.09 -51.26 -2.09 37.74 324.91 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 318.26 13.35 23.843 &lt;2e-16 *** ## armTreatment 32.83 20.72 1.585 0.119 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 74.32 on 51 degrees of freedom ## Multiple R-squared: 0.04693, Adjusted R-squared: 0.02824 ## F-statistic: 2.511 on 1 and 51 DF, p-value: 0.1192 On average, those in the Treatment group (loud distractions) had reaction times that were 32.83 milliseconds higher than those in the Control group. Is a difference of 32.83 ms a “real difference”? What do we mean by “real difference”? We estimated this difference based on our class sample. This is why the summary() output from R labels the column Estimate. In reality, we care about understanding a general truth about the broader adult population. True population value: the value of the model coefficient that we would observe if we fit the model using the entire population of interest. Remember that model coefficients give us changes/comparisons of interest. “Real difference” means a meaningful difference in the broader population Maybe a meaningful difference is simply not zero. Maybe a meaningful difference is one that is of a certain magnitude or higher. e.g., at least 100 ms. What is our best guess of the true population value? Our estimate itself! (Our estimate from our sample.) Hmm…but what if our sample was weird/peculiar somehow? Would most other samples have generated similar estimates? Another way of expressing this: how much do estimates vary from sample to sample? If a lot: many samples estimate a difference with the opposite sign as mine! Not reassuring! If not a lot: most samples at least agree on the sign of the difference. More reassuring that I got the sign of the true population value correct. Bootstrapping to estimate sampling variation Can’t resample the population (easily), so let’s resample our sample! Goal: Only care about measuring variation in estimates from sample to sample. Think range, standard deviation as metrics Don’t care about the center of the estimates from sample to sample. (Because we’re resampling our sample, the center will essentially be equal to our original estimate.) The bootstrapping procedure Step 1: Resample our sample a large number \\(B\\) (\\(\\approx\\) 1000) times. The resamples must be of the same size as the original. (Increasing the sample size decreases the amount of sampling variation.) This resampling must be done with replacement. (Otherwise we’ll get the same resample every time.) Step 2: Fit the model of interest in each of the \\(B\\) resamples. Step 3: Obtain the coefficients of interest. We now have \\(B\\) (1000) sets of coefficients. # Resample the data and estimate the difference set.seed(89) resampled_coeffs &lt;- replicate(1000, { experiment_resampled &lt;- experiment %&gt;% sample_n(size = nrow(experiment), replace = TRUE) mod &lt;- lm(rtime ~ arm, data = experiment_resampled) coefficients(mod) }) # Put the resampled coefficients into a dataset bootstrap_data &lt;- resampled_coeffs %&gt;% t() %&gt;% as.data.frame() # What does bootstrap_data look like? head(bootstrap_data) ## (Intercept) armTreatment ## 1 324.0714 19.648571 ## 2 318.7273 37.122727 ## 3 327.3182 19.843109 ## 4 314.7429 6.090476 ## 5 313.8077 21.896011 ## 6 331.3784 37.621622 # Plot the distribution of the coefficient of interest ggplot(bootstrap_data, aes(x = armTreatment)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. There are two main methods to quantify the amount of sampling variation. Method 1: Use the middle 95% of these coefficients # The $ pulls out the armTreatment variable quantile(bootstrap_data$armTreatment, probs = c(0.025,0.975)) ## 2.5% 97.5% ## -7.614275 77.785810 # The [[&quot;armTreatment&quot;]] also pulls out the armTreatment variable quantile(bootstrap_data[[&quot;armTreatment&quot;]], probs = c(0.025,0.975)) ## 2.5% 97.5% ## -7.614275 77.785810 Middle 95% is the range from -7.6 to 77.8 ms. This is the 95% bootstrap confidence interval. This interval can be interpreted as a range of plausible values for the true population value (difference in reaction times: Treatment - Control). After all, it represents a range of estimates from “other samples”. A sample’s estimate is our best guess for the true population value. Do we have evidence for a real difference? What is our criteria for a real difference? Not zero? We do not have evidence for a real difference. Zero is a plausible value for the true population difference because it is in the interval. Suppose our 95% bootstrap confidence interval (CI) had been (90, 200) Criterion: a real difference is not zero We do have evidence for a real difference. Zero is not a plausible value for the true population value because it is not in the interval. Another criterion: a real difference is at least 100 ms. We do not have evidence for a real difference because it is plausible that the true difference in the broader population is a value less than 100 ms (e.g., 90, 91, 92 are all plausible because they are in the interval). Method 2: If the 1000 coefficients follow a normal distribution… The middle 95% is given by: -2 SDs to +2 SDs SD = standard deviation of the 1000 coefficients. # SD measures the spread of the coefficient estimates across samples sd(bootstrap_data$armTreatment) ## [1] 21.87694 # It&#39;s quite close to the Standard Error (Std. Error)! # Not a coincidence! summary(original_model) ## ## Call: ## lm(formula = rtime ~ arm, data = experiment) ## ## Residuals: ## Min 1Q Median 3Q Max ## -117.09 -51.26 -2.09 37.74 324.91 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 318.26 13.35 23.843 &lt;2e-16 *** ## armTreatment 32.83 20.72 1.585 0.119 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 74.32 on 51 degrees of freedom ## Multiple R-squared: 0.04693, Adjusted R-squared: 0.02824 ## F-statistic: 2.511 on 1 and 51 DF, p-value: 0.1192 Method 1 is the most general (preferred way). We’ll see Method 2 in another way later in the semester. Bootstrapping FAQ Isn’t it a problem that we could sample the same case multiple times? e.g., Case 12 is sampled 3 times. This just means that Case 12 is representative of 3 people in this sample. What’s the magic number of resamples? 1000 will be good enough for us. Too little and we won’t get a good estimate of sampling variation. Too large and the process will take too long. Why the middle 95% instead of 100% (the full range)? Ideally, we want the histogram above to show every possible sample from the broader population – there are infinitely many of these! The full distribution (which is only approximated by the histogram) goes from \\(-\\infty\\) to \\(+\\infty\\)! The 100% range would tell us: a plausible set of values for the true population value is \\((-\\infty, +\\infty)\\). Not very useful! Assumptions of bootstrapping (as described by the procedure above) We assume that our sample is representative of the broader population. We assume that our cases are independent. More precisely, we assume that our residuals are independent. Once we subtract off the “explainable part” of the response (leaving the residual), these errors (residuals) for different cases are not related to each other. Examples of violations of independence: Cases are repeated measurements for an individual. (e.g., health measurements at multiple time points) Cases share some spatial relatedness. Cases share some temporal relatedness. Want to know more? Take Correlated Data at Mac! Exercises A template RMarkdown document that you can start from is available here. Data setup library(readr) library(ggplot2) library(dplyr) experiment &lt;- read_csv(&quot;https://www.dropbox.com/s/cwhhr0vjibw64tx/experiment_spring_2020.csv?dl=1&quot;) # Rename the variables colnames(experiment) &lt;- c(&quot;timestamp&quot;, &quot;arm&quot;, &quot;rtime&quot;, &quot;vid_games&quot;, &quot;sports&quot;, &quot;drive&quot;, &quot;hand&quot;) # Clean up the &quot;hand&quot; variable labels experiment &lt;- experiment %&gt;% mutate( hand = case_when( hand==&quot;Right-handed&quot; ~ &quot;Right&quot;, hand==&quot;Left-handed&quot; ~ &quot;Left&quot; ) ) Exercise 1 Could being a video gamer, athlete, or regular driver confound the relationship between treatment and reaction time? Make plots to justify. If we had performed this experiment in a much larger sample, would you expect these variables to be confounders? Explain. (Note: we’ll revisit the study design aspect (randomized experiment) in more detail next class.) Based on your investigations, fit a model that will allow you to estimate the isolated (causal) effect of loud distractions on reaction times. Obtain a 95% bootstrap confidence interval for this isolated (causal) effect. In order to ensure that your bootstrapping results don’t keep changing each time you run the code, put set.seed(155) at the top of the code chunk where you perform bootstrapping. If you get an error about missing values, add , na.rm = TRUE to the quantile() function. What is the magnitude of a real, meaningful difference to you? Does your confidence interval provide evidence for a real difference? Briefly explain. Exercise 2 Research question: Does the isolated (causal) effect of distractions differ among video gamers and non-gamers? Answering this question involves a more complex model than we have seen before. Fit the model below, and first make sure that you understand how the R syntax rtime ~ arm*vid_games + sports translates to the coefficients that result in the full model formula. mod_interact &lt;- lm(rtime ~ arm*vid_games + sports, data = experiment) summary(mod_interact) Write the simpler model formulas for (1) non-gamers and (2) video gamers. Verify that these model formulas are multiple linear regression models. (Before, when our interaction models only included the two variables that were interacting, this process would give us simple linear regression models.) Interpret the armTreatment coefficient in the non-gamer and the gamer model formulas. Based on this, explain why the armTreatment:vid_gamesYes coefficient answers this research question. Obtain a 95% bootstrap confidence interval for the armTreatment:vid_gamesYes coefficient. (Use set.seed(155) again in your code chunk. If you get an error about missing values, add , na.rm = TRUE to the quantile() function.) What is the magnitude of a real, meaningful difference in the causal effect for you? Does your confidence interval provide evidence for a real difference? Briefly explain. "],["causal-inference.html", "Topic 13 Causal Inference Learning Goals Discussion Exercises", " Topic 13 Causal Inference Learning Goals Connect the idea of a causal effect to the idea of confounding Use causal diagrams to identify which variables should be “controlled”/“adjusted” for in analyses Use regression models to answer causal questions Discussion “Correlation does not imply causation.” Your instructor finds this saying vacuous and “avoidist”. “Avoidist”: cultural tendency to (unreasonably) avoid talking about a topic Why do people always jump to this saying? Shoe size and reading ability are positively correlated Ice cream sales and drownings Can you think of others? Question: What causal diagrams are behind these situations? Holding age constant would show zero effect of shoe size on reading ability Holding temperature constant would show zero effect of ice cream sales on drownings In most research settings, there is an arrow between the variable of interest and the response and many potential confounding variables: The goal of causal inference is quantitatively estimating the effect of \\(X\\) on \\(Y\\) along the direct arrow. The “isolated effect” that we’ve been referring to is actually another way of phrasing the causal effect. If we can measure all confounders, including all confounders in a regression model allows us to hold those variables constant. Also called “controlling for” confounders Also called “adjusting for” confounders In a non-interaction model, \\(\\beta_1\\) is of interest (Y ~ X + C1 + C2): \\[ E[Y] = \\beta_0 + \\beta_1\\,X + \\beta_2\\,C_1 + \\beta_3\\,C_2 \\] An interaction model also allows us to hold the confounders constant (Y ~ X*C1 + C2): \\[ E[Y] = \\beta_0 + \\beta_1\\,X + \\beta_2\\,C_1 + \\beta_3\\,X\\times C_1 + \\beta_4\\,C_2 \\] Or Y ~ X*C2 + C1: \\[ E[Y] = \\beta_0 + \\beta_1\\,X + \\beta_2\\,C_2 + \\beta_3\\,X\\times C_2 + \\beta_4\\,C_1 \\] (You’ll practice in the Exercises.) Overadjustment bias It is tempting to put as many variables as we can into models to hold constant any potential confounders. It is very easy to do harm here! It is possible to overadjust. To understand the causal effect of the flu shot, we should adjust for (hold constant) age and socioeconomic status. Do we really want to adjust for immune cell level in the time period after the shot? Immune cell levels are a mediator of the effect of the flu shot on subsequent flu. This variable lies on a causal pathway between the variable of interest and the response. Would we ever want to adjust for mediators? The total effect of the flu shot on subsequent flu is the effect through both the immune cells and hand washing pathways. If we adjust only for age and SES (hold them constant), we’ll estimate the total effect. The direct effect (not pictured) would be the effect along an arrow directly from Flu shot to Flu. We are interested in the indirect effect through Immune cells. If we adjust for age, SES, and hand-washing, we can estimate this indirect effect. Instead of… “Correlation does not imply causation.” …let’s say “Properly adjusted correlations are causation.” Exercises You won’t need R for these conceptual exercises. Exercise 1 Draw a causal diagram corresponding to a study of how yoga participation affects stress levels. What confounding variables are likely present? What possible mediating variables would we want to adjust for in our analysis? What mediating variables would not want to adjust for? Exercise 2 Suppose that in the yoga study, we conclude that we need to adjust for the confounding variables of age and prior lifetime history of exercise. The variables recorded are: yoga: yes/no participation stress: hours per week under stress age: in years exercise: in hours per week Write out the multiple regression model (without interaction) that could be used to estimate the causal effect of yoga on stress levels. Is there a real, meaningful effect of yoga on stress levels? Describe in detail how we could answer the question. Suppose you made a plot that indicates an interaction between yoga and age in predicting stress levels (age and exercise are still confounders). What would this plot look like? Continuing from (c), consider the research question: “How does the causal effect of yoga on stress differ across ages?” Write down the regression model formula that would allow you to answer this research question. There isn’t necessarily a single coefficient from this model that will answer the question, but describe how you could use the model to make predictions that would answer this research question. Exercise 3 Suppose now that yoga and age are now measured differently: yoga: hours per week of participation age: two categories “young” and “old” Suppose you made a plot that indicates an interaction between yoga and age in predicting stress levels (age and exercise are still confounders). What would this plot look like? Continuing from (a), consider the research question: “How does the causal effect of yoga on stress differ across ages?” Write down the regression model formula that would allow you to answer this research question. There are two coefficients in this model that are of interest. What are they, and how can we interpret them in a contextually meaningful way? Describe how we could assess if there is a real, meaningful difference in effects of yoga between the young and old. "],["midterm-review.html", "Topic 14 Midterm Review Core Themes Additional Exercises", " Topic 14 Midterm Review Core Themes Misleading Visualizations: How do different visualizations hide / fail to show certain aspects of the data? Summary statistics: How do summary statistics hide / fail to show certain aspects of the data? Coefficients in simple linear regression models Multiple R-squared Multicollinearity Confounders and mediators Prediction vs. Explanation Metrics for predictive quality Goal: prediction Include all variables that actually predict the response Does multicollinearity / redundancy matter? Do confounders / mediators matter? Goal: explanation Does multicollinearity / redundancy matter? Do confounders / mediators matter? Additional Exercises Exercise 1 Suppose that we want to know the causal effect of \\(X\\) on \\(Y\\), and there is a single confounder \\(C\\). Can the model Y ~ X+C answer this research question? Can the model Y ~ X*C answer this research question? Make sure that you know how to interpret the coefficients in both of the above models regardless of the type of variable \\(X\\) and \\(C\\) are. Exercise 2 Consider a categorical predictor of interest \\(X\\), response \\(Y\\), and a quantitative confounder \\(C\\). Consider the following 3 situations: Situation 1: Confounding: no. Interaction: yes. Situation 2: Confounding: yes. Interaction: no. Situation 3: Confounding: yes. Interaction: yes. Situation 4: Confounding: no. Interaction: no. For each situation draw a single plot that clearly shows the situation. After you draw these single plots, think about what the plots would look like if the situation weren’t so clear and about what additional plots would be helpful in that circumstance. Exercise 3 Consider the process of performing bootstrapping. Identify all points in the process that could be performed incorrectly and describe the implications of such errors. We view our bootstrap confidence intervals as ranges of plausible values for the true population value. What is the rationale for this? "],["probability-essentials.html", "Topic 15 Probability Essentials Learning Goals Exercises", " Topic 15 Probability Essentials Learning Goals Use and interpret unconditional and conditional probabilities Use and interpret odds as another form of measuring chances Exercises Exercise 1: Binary responses Binary (2 category) response variables are common in statistical applications. Name some possible predictors for each response variable below. y = voted / didn’t vote x: y = an email message is spam / not spam x: y = an individual develops / does not develop disease x: Exercise 2: Probability Identify examples of events for which: \\(p = 0\\) \\(p = 0.5\\) \\(p = 1\\) Exercise 3: Odds from probability Calculate the odds of each event below where the events are listed in order of most to least likely: event \\(p =\\) event probability odds it rains tomorrow 0.99 roll a 6-sided die &amp; see 1, 2, 3, or 4 4/6 flip a coin &amp; see Heads 0.5 roll a 6-sided die &amp; see 5 or 6 2/6 tomorrow is above freezing 0.01 Interpret one of the odds that is less than 1, and interpret one of the odds that is greater than 1. Exercise 4: Probability from odds Note that if given odds, we can obtain probabilities with: \\[ p = \\frac{\\hbox{odds}}{1+\\hbox{odds}} \\] Suppose that sports analysts give a certain team a 2-to-1 odds of winning the next game. Before doing any calculations, what does this imply about the corresponding probability of the team winning: is it less than, equal to, or greater than 0.5? Calculate the corresponding probability of the team winning. A story in National Geographic places the odds of being struck by lightning in one’s lifetime at 1-to-3000. Before doing any calculations, what does this imply about the corresponding probability of being struck by lightning: is it less than, equal to, or greater than 0.5? Calculate the corresponding probability of being struck by lightning. (Extra) Verify the algebra behind the probability from odds formula above. Exercise 5: Maryland Renaissance Fair At 2017 Maryland Renaissance Fair, your instructor was attending a magic show in which the magician announced that he would magically pull out an audience member’s chosen card from a 52 card deck. He in fact did so (cool!) but indicated emphatically at the end, “What are the odds of that? 1 in 52. Pretty amazing huh?” (not cool!) Your instructor wanted to exclaim “….!” Fill in the dots with an appropriate exclamation for the magician. Exercise 6: Disease screening The diagnostic tests used to screen for disease are used for all different types of disease (infectious, chronic, long-term). In this exercise, we’ll use probability tools to evaluate the accuracy of such tests. Suppose that we have the following information about the rarity of the disease (\\(D = 1\\) if someone has the disease and \\(D = 0\\) otherwise) and characteristics of the diagnostic test (e.g., a blood test): \\(P(D = 1) = 20\\%\\): also known as the prevalence of the disease \\(P(\\hbox{Test positive} \\mid D = 1) = 99\\%\\): also known as the sensitivity of the test \\(P(\\hbox{Test negative} \\mid D = 0) = 95\\%\\): also known as the specificity of the test Give a contextual interpretation of the sensitivity and specificity of the diagnostic test. Suppose that there are 10,000 people in the population. Fill out a table with 2 rows (test positive and test negative) and 2 columns (has disease, no disease) giving the numbers of people expected to be in these 4 categories. Calculate and interpret \\(P(D = 1 \\mid \\hbox{Test positive})\\). (Also known as the positive predictive value (PPV) of the test.) Calculate and interpret \\(P(D = 0 \\mid \\hbox{Test negative})\\). (Also known as the negative predictive value (NPV) of the test.) Repeat part (b) except suppose that the disease is more rare: \\(P(D = 1) = 1\\%\\). For doctors and patients who are viewing diagnostic test results, do you think that sensitivity and specificity are more useful or that PPV and NPV are more useful for making clinical decisions? Make a general conclusion about how the rarity of the disease affects the PPV and NPV and why this is important. "],["simple-logistic-regression.html", "Topic 16 Simple Logistic Regression Learning Goals Warm-up Exercises", " Topic 16 Simple Logistic Regression Learning Goals Construct simple logistic regression models in R Interpret coefficients in simple logistic regression models Use simple logistic regression models to make predictions Describe the form (shape) of relationships on the log odds, odds, and probability scales Warm-up Navigate to: PollEv.com/lesliemyint417 Warm up questions and answers: If I want to estimate P(Vote = yes | Democrat = yes), who should be counted in the numerator and denominator? A. Denominator: all voters. Numerator: Democrats who are voters. B. Denominator: all Democrats who are voters. Numerator: all voters. C. Denominator: all Democrats. Numerator: all voters. D. Denominator: all Democrats. Numerator: Democrats who are voters. Answer: D Which of the following is a logistic regression model describing how voting is related to age? A. P(Vote = Yes) = B0 + B1 Age B. Odds(Vote = Yes) = B0 + B1 Age C. ln(Odds(Vote = Yes)) = B0 + B1 Age D. e^P(Vote = Yes) = B0 + B1 Age E. e^Odds(Vote = Yes) = B0 + B1 Age Answer: C Suppose that the odds of an event increases as a predictor X increases. What can be said about the probability of the event as X increases? A. Probability increases B. Probability increases initially but then decreases C. Probability decreases Answer: A Suppose the log odds of an event decreases as X increases. What can be said about the corresponding probability? A. Probability increases B. Probability increases initially but then decreases C. Probability decreases Answer: C Consider the logistic regression model log(odds(disease = Yes)) = -2 + 0.5*ExposedYes. What are the odds of disease in those not exposed to an environmental hazard? A. -2 B. 0.5 C. -1.5 D. \\(e^{-2}\\) E. \\(e^{0.5}\\) F. \\(e^{-1.5}\\) Answer: D Same model: log(odds(disease = Yes)) = -2 + 0.5*ExposedYes. How do the odds of disease compare in the exposed and unexposed? A. Exposed have 0.5 times the odds of the unexposed B. Exposed have 0.5 lower odds than the unexposed (difference) C. Exposed have e^0.5 times the odds of the unexposed D. Exposed have e^0.5 lower odds than the unexposed (difference) Answer: C Consider the model log(odds(Disease = Yes)) = B0 + B1*ExposedYes. If the exposed and unexposed have the same chance of having disease, what would you expect about B1? Answer: B1 = 0, e^B1 = 1 Exercises A template RMarkdown document that you can start from is available here. We’ll look at the O-ring data described in the video. Load the data and necessary packages as follows: library(readr) library(dplyr) library(ggplot2) oring &lt;- read_csv(&quot;https://www.macalester.edu/~ajohns24/data/NASA.csv&quot;) Let’s get acquainted with the data and make a few exploratory plots: dim(oring) head(oring) # Univariate visualization of Broken # Univariate visualization of Temp # Visualization of Broken and Temp Exercise 1 We want to model Broken as a function of Temp. Write down the logistic regression model formula. Try to do these without referring to notes. We can fit logistic regression models in R using the glm() function. The “lm” part of “glm” stands for “linear model” (just like the lm() function), and the “g” stands for “generalized”. (The left hand side of the model has been made more general than just \\(E[Y]\\).) Also note that we need to supply the argument family = \"binomial\". oring_mod &lt;- glm(Broken ~ Temp, data = oring, family = &quot;binomial&quot;) summary(oring_mod) We’ll focus primarily on the output in the coefficients table. Interpret the intercept and the temperature coefficient on the log scale in a contextually meaningful way. What concern arises in interpreting the intercept? Interpret the coefficients on the natural scale by exponentiating. Use the exp() function to do this. (e.g., exp(3) gives \\(e^3\\).) Use this model to make predictions about a 60 degree day: Predict the log odds of O-ring failure Predict the odds of O-ring failure Predict the probability of O-ring failure. Also write this probability using conditional probability notation. Exercise 2 When you use glm(), R by default will use Broken = 1 as the event of interest (as opposed to Broken = 0). Suppose that we were to fit the logistic regression model where Broken = 0 became the event of interest. Mathematically work out what the new values of the model coefficients will be. Check your work by replacing the glm() model formula with Broken==0 ~ Temp. Exercise 3 Let’s visualize the model’s predictions. The code below adds the predicted log odds to the original oring dataset. Complete the code to also add the predicted odds and probabilities. oring &lt;- oring %&gt;% mutate( log_odds = predict(oring_mod), odds = ???, # Hint: you can use log_odds in this expression prob = ??? ) Construct plots of the log odds, odds, and probability as a function of temperature. We can also zoom out to see a broader temperature range. Describe the shape of the relationship between the probability of an O-ring breaking and temperature. ggplot(oring, aes(x = Temp, y = Broken)) + geom_point() + geom_smooth(method = &quot;glm&quot;, method.args = list(family = &quot;binomial&quot;), se = FALSE, fullrange = TRUE) + labs(y = &quot;probability of breaking&quot;) + lims(x = c(0,100)) Note: the function shown in this plot is called the logistic function which is where logistic regression gets its name. Exercise 4 We have the following data on whether or not individuals were exposed to an environmental hazard and whether or not they developed a certain disease within 10 years. Disease No disease Total Exposed 5 495 500 Unexposed 5 995 1000 Total 10 1490 1500 Write down the logistic regression model formula corresponding and estimate the coefficients by hand using data from the table. (Use a variable called exposed that is equal to 1 if exposed and 0 if not.) "],["multiple-logistic-regression.html", "Topic 17 Multiple Logistic Regression Learning Goals Exercises", " Topic 17 Multiple Logistic Regression Learning Goals Construct multiple logistic regression models in R Construct and interpret visualizations to inform model building Interpret multiple logistic regression model output Exercises A template RMarkdown document that you can start from is available here. We will be looking at data from the Add Health study (https://cpc.unc.edu/projects/addhealth), a national survey of adolescent health. Research question: What is the causal effect of adolescent marijuana smoking on adulthood cigarette smoking? The following variables are in the dataset: exposure: Indicator for whether or not marijuana was smoked in adolescence. 1=yes, 0=no. (Main predictor of interest.) smoke: Indicator for whether the individual smoked in adulthood. 1=yes, 0=no. (Response variable.) age: Age at study entry (continuous) male: Indicator for whether the individual was male. 1=yes, 0=no. white: Indicator for whether the individual was White. 1=yes, 0=no. susp: Indicator for whether the individual was ever suspended from school. 1=yes, 0=no. mathG: Math grade (1 to 4 corresponding respectively to A to D) readG: Reading grade (1 to 4 corresponding respectively to A to D) parentED: Parent education (1 to 5 corresponding respectively to less than high school, high school, vocational school, some college, and college graduate and beyond). housesmoke: Indicator for the presence of a cigarette smoker in the individual’s household. 1=yes, 0=no. library(readr) library(ggplot2) library(dplyr) addhealth &lt;- read_csv(&quot;https://www.dropbox.com/s/h09nq0nwgx8eioz/addhealth.csv?dl=1&quot;) Peek at the first few rows: head(addhealth) Note: Throughout these exercises, you’ll want to use factor() within visualizations and model formulas to force R to treat a variable as categorical (rather than quantitative). Exercise 1 Let’s get a feel for the main variables of interest. Construct and interpret appropriate univariate visualizations of adolescent marijuana smoking and adulthood cigarette smoking. Exercise 2 Construct and interpret an appropriate visualization of the relationship between exposure and smoke. Based on your visualization what would you expect about the coefficient in an appropriate model of smoke ~ exposure? What would you expect about the 95% bootstrap confidence interval? Fit the appropriate model, and interpret the coefficient of interest on the natural scale. Construct a 95% bootstrap confidence interval for the coefficient (on the log scale). Transform the confidence interval to the natural scale by exponentiating both endpoints. If we define a meaningful effect as one that has an odds ratio of at least 1.5, do we have evidence for a meaningful effect of adolescent marijuana smoking in the broader population? Exercise 3 That previous analysis ignored the “causal” part of the question! Looking through the variables measured, what variables might be confounders and what might be mediators? Make appropriate plots to determine whether housesmoke might confound the relationship between adolescent marijuana smoking and adulthood cigarette smoking. Based on your results from part (b), fit an appropriate model, and interpret the coefficient of interest on the natural scale. Construct a 95% bootstrap confidence interval for the coefficient on the natural scale. Interpret the interval (what information does it contain?), and use it to determine whether we have evidence for a real, meaningful causal effect of adolescent marijuana smoking in the broader population. "],["sampling-distributions-and-the-normal-distribution.html", "Topic 18 Sampling Distributions and the Normal Distribution Learning Goals Exercises", " Topic 18 Sampling Distributions and the Normal Distribution Learning Goals Describe the information contained in sampling distributions Use normal distribution models of sampling distributions to make probability statements about sample estimates Exercises A template RMarkdown document that you can start from is available here. We’ll continue working with data from the Add Health study to understand how the risk of adulthood cigarette smoking is related to adolescent marijuana smoking. library(readr) library(dplyr) library(ggplot2) addhealth &lt;- read_csv(&quot;https://www.dropbox.com/s/h09nq0nwgx8eioz/addhealth.csv?dl=1&quot;) Let’s pretend that the 1541 people in this dataset represent the full broader population of interest. When we fit the logistic regression model below, the coeffients represent the true population values of these quantities: population_mod &lt;- glm(smoke ~ exposure, data = addhealth, family = &quot;binomial&quot;) summary(population_mod) We would not normally have access to this full population, so let’s draw a random sample of 500 people from it to obtain our study’s data: set.seed(155) addhealth_sample &lt;- addhealth %&gt;% sample_n(size = 500, replace = FALSE) We can fit the same model of interest in our “sample”: sample_mod &lt;- glm(smoke ~ exposure, data = addhealth_sample, family = &quot;binomial&quot;) summary(sample_mod) Exercise: Based on the model output, how would you expect the sampling distributions of the intercept and the exposure coefficient to compare? Exercise: With the luxury of having the “full population”, we can set out to obtain the sampling distribution. Modify our traditional code for bootstrapping to obtain 1000 different samples of size 500 from the full population. Make plots that show the distribution of the intercept and exposure coefficient estimates across samples. Does your expectation from the previous hold up? How close are the standard deviations of the estimates to the standard errors from our sample’s model? (You can use the sd() function and repeated_samples[[\"name_of_coefficient\"]] will pull out a specific coefficient.) set.seed(155) repeated_samples &lt;- replicate(1000, { }) repeated_samples &lt;- repeated_samples %&gt;% t() %&gt;% as.data.frame() head(repeated_samples) # Plots # For the intercept ggplot(repeated_samples, aes(x = `(Intercept)`)) + ??? # For the exposure coefficient Exercise: Repeat the above process for samples of size 1000 from the population. How do the distributions compare? Exercise: It turns out that sampling distributions for regression coefficients are often normally-distributed with mean equal to the true population value and standard deviation equal to the standard error for that coefficient. Based on the model output from population_mod and sample_mod, provide a answer for the following based on samples of size 500: 68% of samples will generate estimates between what two values? 95% of samples will generate estimates between what two values? 99.7% of samples will generate estimates between what two values? "],["central-limit-theorem.html", "Topic 19 Central Limit Theorem Learning Goals Discussion Exercises", " Topic 19 Central Limit Theorem Learning Goals Use the Central Limit Theorem to construct confidence intervals Use confidence intervals to answer research questions Make quantitative predictions about how changing sample size Discussion In the video/slides, we saw Exercises A template RMarkdown document that you can start from is available here. Exercise 1 We know from the Central Limit Theorem (CLT) that at large enough sample sizes (roughly \\(n \\geq 30\\)): \\[ \\hat\\beta \\sim N(\\beta, \\hbox{SE}^2) \\] Given a property of the normal distribution, complete the following probability statement: \\[ P(\\hbox{???} &lt; \\hat\\beta &lt; \\hbox{???}) = 0.95 \\] Rearrange the probability statement above so that it looks like: \\[ P(\\hbox{something with } \\hat\\beta \\hbox{ and } SE &lt; \\beta &lt; \\hbox{something with } \\hat\\beta \\hbox{ and } SE ) = 0.95 \\] Explain how your work in (b) shows how we can use coefficient estimates and their standard errors to construct a 95% confidence interval. Would a 68% confidence interval be narrower or wider than a 95% confidence interval? What about a 99.7% confidence interval? Note: Technically, in linear regression, the sampling distribution of the coefficients follows the T distribution, but at typical sample sizes where the CLT applies (\\(n \\geq 30\\)), the T distribution is nearly indistinguishable from the normal distribution. Exercise 2 Based on the CLT, we know that standard error has a certain relationship with sample size. Suppose that I wanted the standard error of my estimate to be \\(A\\) times smaller. How would my sample size have to change to achieve this? Interlude: Interpreting confidence intervals Our work in Exercise 1 shows that we can create 95% confidence intervals with: \\[ \\hbox{estimate} \\pm 2\\times\\hbox{std. error} \\] That is, we can interpret the probability statement below: \\[ P\\left(\\hat\\beta-2SE &lt; \\beta &lt; \\hat\\beta+2SE \\right) = 0.95 \\] as saying: the probability that a 95% confidence interval from a random sample contains the true population value is 95%. The correct interpretation: 95% of all possible samples will produce 95% CI’s that cover the true value. The other 5% are based on unlucky samples that produce unusually low or high estimates. The INCORRECT interpretation: We cannot say that “there’s a 95% chance that the true population value is in the 95% CI from this particular sample.” Technically, the population value is either in the interval or it’s not, so the probability is simply 1 or 0. e.g., If the true population value is \\(\\beta = 1\\), and my CI is (2,4), there is a 0% probability that the truth is in my interval. If my CI were (0.5,3.5), there is a 100% probability that the truth is in this interval. Note that this also applies to bootstrap confidence intervals, and 95% is called the coverage probability or confidence level. Exercise 3 In addition to using the reported estimate and standard error from our model output, we can use a handy function in R called confint() to compute confidence intervals. If we fit a model called mod, we can use confint(mod, level = 0.95) to obtain 95% confidence intervals. We’ll practice with a dataset containing information on house prices in upstate New York. library(readr) library(dplyr) library(ggplot2) homes &lt;- read_tsv(&quot;http://sites.williams.edu/rdeveaux/files/2014/09/Saratoga.txt&quot;) # Create an indicator of whether or not a house has a fireplace homes &lt;- homes %&gt;% mutate(HasFireplace = Fireplaces &gt; 0) Do we have evidence for a real, meaningful effect of square footage (Living.Area) on Price for houses with a fixed Age? A meaningful effect is at least 10 dollars per square foot. Interpret the relevant coefficient, and provide a 99% confidence interval to support your answer. Does your confidence interval contain the true population value of the relevant regression coefficient? Repeat parts (a) and (b) for the research question: Do we have evidence for a real, meaningful effect of Age on the chance of a home having a fireplace at fixed square footages? A meaningful effect is one with an odds ratio of at least 1.1 if the effect is positive or at most 0.9 is negative. "],["linear-regression-assumptions.html", "Topic 20 Linear Regression Assumptions Learning Goals Discussion Exercises Exercise 1 Exercise 2 Exercise 3 Exercise 4", " Topic 20 Linear Regression Assumptions Learning Goals Use visualizations to check the assumptions behind linear regression models Transform variables approriately to help models better meet assumptions Predict how properties of statistical inference proceudres will vary based on the degree to which assumptions are met Discussion We’ve written linear regression models as: \\[ E[Y] = \\beta_0 + \\beta_1x_1 + \\cdots + \\beta_p x_p \\] This is equivalent to how it was written in the video: \\[ Y = \\beta_0 + \\beta_1x_1 + \\cdots + \\beta_p x_p + \\varepsilon \\] \\(\\varepsilon\\) stands for the error, or the residuals, and the 4 key assumptions of linear regression can be compactly summarized by the following statement: \\[ \\varepsilon \\stackrel{ind}{\\sim} N(0, \\sigma^2) \\] Independence Trend Homoskedasticity Normality Normality of the residuals is actually least important of the 4 because of the Central Limit Theorem. However, violations of normality usually lead to violations of homoskedasticity. Assumptions serve to ensure that statistical inference procedures (e.g., confidence intervals, hypothesis tests–coming up next!) “work as advertised”: The process of creating a 95% CI is a procedure (add and subtract about 2 standard errors from the estimate). It “works as advertised” if in 95% of possible samples it creates intervals that contain the true population value. (The other 5% of samples are unlucky ones.) It does not “work as advertised” if, for example, only 90% of possible samples result in intervals (95% CIs) that contain the true population value. Exercises A template RMarkdown document that you can start from is available here. # Load required packages library(readr) library(ggplot2) library(dplyr) # Read in the data homes &lt;- read_tsv(&quot;http://sites.williams.edu/rdeveaux/files/2014/09/Saratoga.txt&quot;) # Look at the first 6 rows head(homes) We will pretend that the homes dataset contains the full population of New York houses. Let’s draw a random sample of 500 houses from the “population”. We can do this with the sample_n() function available in the dplyr package: # Randomly sample 500 homes set.seed(155) homes_sample &lt;- sample_n(homes, size = 500) Exercise 1 Do you think the independence assumption holds? Briefly explain. Note: violations to the indpendence assumption are beyond the scope of our course, but appropriate methods are handled in Mac’s Correlated Data class (STAT 452). Exercise 2 In this exercise, we’ll build an initial model of Price versus Age. We’ll aim to improve it in the next exercise. Using our sample (homes_sample), visualize the relationship between house price and house age. How would you describe the overall shape of the trend? Is it linear? Using our sample (homes_sample), fit a linear regression model where Price is predicted by Age. Call this model mod1. Check the trend and homoskedasticity assumptions by plotting the residuals versus the fitted (predicted) values. The points should be evenly scattered around the \\(y = 0\\) line. Do you think these assumptions are met? # Put the residuals and predicted values into a dataset mod1_output &lt;- data.frame( residual = residuals(mod1), predicted = fitted.values(mod1) ) # Plot ggplot(mod1_output, aes(???)) + ??? + geom_hline(yintercept = 0, color = &quot;red&quot;) # Add the y = 0 line Check the normality assumption by making a QQ-plot of the residuals. In a QQ-plot, each residual (y-axis) is plotted against its theoretical corresponding value from a standard normal distribution (\\(N(0,1^2)\\)) on the x-axis. That is, the first quartile of the residuals is plotted against the first quartile of \\(N(0,1^2)\\), the median of the residuals is plotted against the median of \\(N(0,1^2)\\), and so on. If the residuals follow a normal distribution, then the points should fall on a line. Do you think the normality assumption holds? ggplot(mod1_output, aes(sample = residual)) + geom_qq() + geom_qq_line() Exercise 3 The diagnostic plots we made above suggest that key assumptions are not being met. Let’s explore how transforming variables can help us meet those assumptions. One of the most common variable transformations that can help fix an unmet homoskedasticity assumption is a logarithmic transformation of the response variable. We will also try to better model the nonlinear shape of the Price vs. Age trend by using a logarithmic transformation. The mutate() function in the dplyr package allows us to create these new transformed variables: homes_sample &lt;- homes_sample %&gt;% mutate( log_price = log(Price), log_age = log(Age + 1) # Some Age&#39;s are 0, so add 1 to prevent log(0), which is undefined ) Fit a linear regression model called mod2 where log_price is predicted by log_age. Using similar code as in Exercise 2, obtain the residuals and fitted values, and store this in an object called mod2_output. Check the trend, homoskedasticity, and normality assumptions for mod2. Do these assumptions seem to hold better for mod1 or mod2? Exercise 4 Now let’s look at the implications of our investigations for statistical inference. Since we have the entire population of New York homes, we can investigate whether or not confidence intervals “work as advertised” for the two models we investigated. Fit the Price ~ Age and the log_price ~ log_age models in the full population. What are the true population values of the Age and log(Age) coefficients? Obtain the 95% confidence intervals for the coefficients in mod1 and mod2 with the confint() function. (Good review: What computations are going on behind the scenes in confint()?) Does the 95% confidence interval “work as advertised” in this case? In part (b), we just looked at one sample. If the 95% CI truly were “working as advertised”, 95% of samples would produce 95% CIs that contain the true population value. Behind the scenes, we have run a simulation study to see how 95% CIs “work” in 1000 different samples of 500 homes. We find that for mod1, 95% CIs contain the true value of the Age coefficient in 935 samples. We find that for mod2, 95% CIs contain the true value of the log_age coefficient in 968 samples. With regards to statistical inference, what can you conclude about assumption violations and fixing those violations? "],["hypothesis-testing.html", "Topic 21 Hypothesis Testing Learning Goals Discussion Exercises", " Topic 21 Hypothesis Testing Learning Goals Explain the logic of hypothesis testing Conduct hypothesis tests in the context of regression models to answer research questions Relate hypothesis testing to confidence interval procedures Interpret quantities related to hypothesis testing Discussion When we fit regression models in R and display the summary() output, the Coefficients table gives two new quantities used in hypothesis testing. By default, a null value of zero is used (i.e., \\(H_0: \\beta=0\\)). For linear regression models: t value: the test statistic called “t” because the sampling distribution of these test statistics follows a t distribution (very closely related to the normal distribution) Pr(&gt;|t|): shorthand for probability that the test statistic is larger in absolute value than the observed test statistic \\(t\\) (\\(|t|\\) represents the absolute value of \\(t\\)). This is the two-sided p-value for the test. &gt; lm(Price ~ Age, data = homes) %&gt;% summary() Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 229728.46 3218.18 71.385 &lt; 2e-16 *** Age ??? 79.66 -7.987 2.5e-15 *** Question: The estimate for Age was deleted by accident! Are we able to fill in that missing information? Why or why not? For logistic regression models, the “t” is instead a “z” because the sampling distribution of coefficients is the normal distribution. (Usually quantities that follow a normal distribution are denoted by “z”.) &gt; glm(smoke ~ exposure, data = addhealth, family = &quot;binomial&quot;) %&gt;% summary() Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -0.86275 0.05805 -14.862 &lt; 2e-16 *** exposure 0.91318 0.19237 4.747 2.06e-06 *** We noted in the video that both confidence intervals and hypothesis tests can answer questions about whether we have evidence for real, meaningful broader population effects. It turns out that decisions made from hypothesis tests with a significance level of \\(\\alpha\\) are equivalent to the corresponding \\(100(1-\\alpha)\\%\\) CI. e.g., Conducting a hypothesis test with a significance level of \\(\\alpha = 0.05\\) is equivalent to conclusion from a 95% CI Exercises A template RMarkdown document that you can start from is available here. We will be using data on 1167 colleges obtained from an edition of the U.S. News College Rankings. For each college, the following variables are given: College: Name of school GradRate: College graduation rate (as a value from 0 to 100) SFRatio: Student-to-faculty ratio AdmisRate: Percentage of applicants accepted (as a value from 0 to 100) FacultyPhD: Percentage of faculty with a PhD (as a value from 0 to 100) Type: School type (Private or Public) Region: Location of school: Midwest, NorthEast, South, or West. State: School state MathSAT: Average Math SAT score of entering first-years VerbalSAT: Average Verbal SAT score of entering first-years ACT: Average ACT score of entering first-years library(readr) library(dplyr) library(ggplot2) colleges &lt;- read_csv(&quot;https://www.dropbox.com/s/efgkjbqeiikzzn7/USNews.csv?dl=1&quot;) Research question: What is the causal effect of student-to-faculty ratios on graduation rates? How does this effect differ across school types? Throughout, use zero as the criteria for a meaningful difference and a significance level of 0.01. Exercise 1 Fit an unadjusted model that ignores any potential confounders. Present a (naïve) answer to the first research question by interpreting the relevant coefficient and conducting an appropriate hypothesis test. What would you expect about the corresponding 99% confidence interval (CI) for the coefficient (whether through bootstrapping or the CLT)? What about the 95% CI for the coefficient? Briefly explain, and check your answer with confint(). Exercise 2 We find that school type (Type) and average ACT scores (ACT) are potential confounders of the relationship between student-to-faculty ratios and graduation rates. Fit an adjusted model that answers the first research question. Give an interpretation for all 4 quantities for the relevant coefficient: the estimate, the standard error, the test statistic, and p-value. Show that you reach the same conclusions with an appropriate confidence interval. Exercise 3 Fit an appropriate model to answer the second research question. Support your response by interpreting the two relevant coefficients and by appropriately using a p-value and a confidence interval. Exercise 4 Suppose we know that the distribution of a test statistic \\(Z\\) “under \\(H_0\\)” (if \\(H_0\\) is true) is the standard normal distribution (mean = 0, SD = 1). This is the case in logistic regression. For what values of the test statistic \\(Z\\) will I reject \\(H_0\\) using \\(\\alpha = 0.05\\) as my p-value cutoff? For what values of the test statistic \\(Z\\) will I reject \\(H_0\\) using \\(\\alpha = 0.32\\) as my p-value cutoff? "],["hypothesis-testing-errors.html", "Topic 22 Hypothesis Testing Errors Learning Goals Exercises", " Topic 22 Hypothesis Testing Errors Learning Goals Explain the trade-offs between type 1 and type 2 errors Explain how different factors affect the power of a hypothesis test Connect concepts of error rates to practical ethical considerations in the conduct of science Exercises Exercise 1 Navigate to this page to perform an interactive investigation on what factors influence statistical power. Under “Settings”, choose the button that solves for power. You will vary the different parameters (one at a time) to understand how these factors affect power. Some context behind this interactive visualization: Visualization is based on a one sample Z-test: This is a test for whether the true population mean equals a particular value. (e.g., true mean = 30) The effect size slider is measured with a metric called Cohen’s d: Cohen’s d = magnitude of effect/standard deviation of response variable Here: how far is the true mean from the null value in units of SD? e.g., If the null value is 30, true mean is 40, and the true population SD of the quantity is 5, the Cohen’s d effect size is (40-30)/5 = 2. What is your intuition about how changing the significance level will change power? Check your intuition with the visualization and explain why this happens. Repeat part (a) for sample size. Repeat part (a) for the effect size. As you reason through this, think first about the impact of the numerator of Cohen’s d (magnitude of the effect). Second, think about the impact of the denominator of Cohen’s d (SD of the response variable). Exercise 2 For each of the situations below, describe what a type I error and a type II error mean in context. Which is worse? \\(H_0\\): defendant is innocent \\(H_A\\): defendant is guilty \\(H_0\\): males and females benefit equally from a drug \\(H_A\\): males and females do not benefit equally from a drug For the second situation, write down a potential linear regression model formula and a logistic regression model formula that could investigate these hypotheses. (You’ll need to add a little more contextual information on your own.) Exercise 3 Visit this page and look at both the comic at the top and the various ways in which researchers have described p-values that do not fall below the \\(\\alpha = 0.05\\) significance level threshold. What ethical consideration is arising here? What are your views on this? (Keep these thoughts in mind as you work on Case Study 2.) Just for fun: a related xkcd comic Exercise 4 Suppose that a hypothesis test yields a p-value of \\(1\\times 10^{-6}\\). Often times, when a p-value falls below the significance level threshold, this is called a statistically significant result. What can you tell about the magnitude of the effect or the uncertainty of the effect from this p-value? (i.e., What can you tell about the coefficient estimate or the standard error?) The notion here is a differentiation between statistical and practical significance. What do you think this idea is referring to? Exercise 5 Take a look at the xkcd comic here. What do you think is going on here? Explain in terms of class concepts. "],["review-1.html", "Topic 23 Review", " Topic 23 Review The following exercises are conceptual exercises connecting to many, but not necessarily all, key ideas from class. For a complete review of topics and relevant coding in R, make sure to look back through our activities, homeworks, quizzes, and exams. Looking back through the learning objectives at the top of each topic page is also a good idea. Exercise 1 Explain how confidence intervals and hypothesis tests are equivalent ways of answering yes/no questions about associations. That is, if we reject the null hypothesis at a significance level of \\(\\alpha\\), what can be said about a related confidence interval? If we don’t reject the null? Exercise 2 Even though confidence intervals and hypothesis tests give the same yes/no conclusions about associations, confidence intervals are seen as more informative. Why this might be the case? Exercise 3 Although confidence intervals are seen as more informative, hypothesis tests provide a nice way of expressing errors in decision making. What are those errors and how do we try to control the rates (probabilities) of those errors? Exercise 4 An often-cited criticism of clinical trials (e.g., to test the efficacy of a new drug) is that because certain types of people tend to be enrolled, the results may not generalize to the broader public. Carefully explain how this is related to the concept of interaction / effect modification. Exercise 5 It is important to consider the units of all variables when interpreting model output. Suppose that the response variable is price, and one of the predictors is a weight of a product in grams. How would you expect the coefficient for weight to change in the following circumstances? Price is measured in thousands of dollars instead of dollars Weight is measured in kilograms instead of grams Exercise 6 In what situations will the intercept of a regression model be meaningful? (There are a few - try to describe as many as you can.) Exercise 7 A p-value can be expressed as a conditional probability. Write an expression for this conditional probability if \\(t\\) is the actual value of the test statistic computed from our sample. Let’s use your response from (a) to examine some common misinterpretations of p-values. Explain why each statement below is false. The p-value is the probability that the null hypothesis is true. A low p-value indicates that the effect is large, or of substantial practical importance. Exercise 8 Cite and explain 3 dangers potentially linked to indiscriminately putting predictors into a regression model. It may be useful to consider both the predictive and explanatory viewpoints of modeling. "]]
